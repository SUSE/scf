releases:
- name: bpm
  version: "1.0.3"
  url: "https://bosh.io/d/github.com/cloudfoundry/bpm-release?v=1.0.3"
  sha1: "5116e990fe1572331dbaf79fa7c5559d0ce793a8"
- name: capi
  version: "1.79.0"
  url: "https://bosh.io/d/github.com/cloudfoundry/capi-release?v=1.79.0"
  sha1: "85d0765ad9815962e46fc99712294c21514e6f7f"
- name: cf-cli
  version: 1.13.0
  url: https://bosh.io/d/github.com/bosh-packages/cf-cli-release?v=1.13.0
  sha1: 9c0cd518a95ef3434e86cef4a35b80e2d3796df0
- name: cf-mysql
  version: 36.15.0
  url: https://bosh.io/d/github.com/cloudfoundry/cf-mysql-release?v=36.15.0
  sha1: 0764d9d6aae7cefd10019437ed83e7715e614633
- name: cf-smoke-tests
  version: 40.0.50
  url: https://bosh.io/d/github.com/cloudfoundry/cf-smoke-tests-release?v=40.0.50
  sha1: d47f4c14d18611025290d9f5e85ae0945fcc986e
- name: cf-syslog-drain
  version: "9.1"
  url: "https://bosh.io/d/github.com/cloudfoundry/cf-syslog-drain-release?v=9.1"
  sha1: "9dd7916e3855a4f9c26bf8a6a610db37addc546c"
- name: cflinuxfs2
  url: "https://bosh.io/d/github.com/cloudfoundry/cflinuxfs2-release?v=1.281.0"
  version: "1.281.0"
  sha1: "1bdcf24c1fb9baf324aebab8ba28f8e64b846305"
- name: cflinuxfs3
  url: "https://bosh.io/d/github.com/cloudfoundry/cflinuxfs3-release?v=0.94.0"
  version: "0.94.0"
  sha1: "c005fa270834b50eb1a5fb689cad8e6442f3cfbd"
- name: credhub
  version: 2.1.4
  url: https://bosh.io/d/github.com/pivotal-cf/credhub-release?v=2.1.4
  sha1: 415badd88a1567e05e0c157b9ec43b7fe86c44e6
- name: diego
  version: 2.30.0
  url: https://bosh.io/d/github.com/cloudfoundry/diego-release?v=2.30.0
  sha1: 7bbe97d294ec26c0603e13755c07cc4bc2a23070
- name: garden-runc
  version: 1.19.1
  url: https://bosh.io/d/github.com/cloudfoundry/garden-runc-release?v=1.19.1
  sha1: 9fca045a0a90cf38cf79feabcc582efd5a20538e
- name: loggregator
  version: "105.0"
  url: https://bosh.io/d/github.com/cloudfoundry/loggregator-release?v=105.0
  sha1: d0bed91335aaac418eb6e8b2be13c6ecf4ce7b90
- name: log-cache
  version: 2.2.0
  url: https://bosh.io/d/github.com/cloudfoundry/log-cache-release?v=2.2.0
  sha1: 1ebecd0adbfc50fdd61309e129b0292deb7e7b24
- name: mapfs
  version: "1.1.0"
  url: "https://bosh.io/d/github.com/cloudfoundry/mapfs-release?v=1.1.0"
  sha1: "1ab1dfb802819ec6cda2d0d60370638d6f878528"
- name: nats
  version: '26'
  url: https://bosh.io/d/github.com/cloudfoundry/nats-release?v=26
  sha1: 2f2c27acdfff81f3519968921686522518ab5783
- name: nfs-volume
  version: "1.5.2"
  url: "https://bosh.io/d/github.com/cloudfoundry/nfs-volume-release?v=1.5.2"
  sha1: "14d019e6fd83139fab5e8ee7f162bf6920235888"
- name: pxc
  url: https://bosh.io/d/github.com/cloudfoundry-incubator/pxc-release?v=0.16.0
  version: 0.16.0
  sha1: eb53d366af2d6e49e8c2ac834191547b2ba44d30
- name: routing
  version: 0.184.0
  url: https://bosh.io/d/github.com/cloudfoundry-incubator/cf-routing-release?v=0.184.0
  sha1: f35eb9884e1c097ff21843e6f2d0eebd22ac2073
- name: statsd-injector
  version: 1.8.0
  url: https://bosh.io/d/github.com/cloudfoundry/statsd-injector-release?v=1.8.0
  sha1: 8b7b7ee31d71175759c0e6e3e8980c1ffbef94d3
- name: loggregator-agent
  version: "3.7"
  url: "https://bosh.io/d/github.com/cloudfoundry/loggregator-agent-release?v=3.7"
  sha1: "67bb1c20a4bb209a1f611ba041cbba8ad1158087"
- name: binary-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/binary-buildpack-release-1.0.32.1.tgz"
  version: "1.0.32.1"
  sha1: "4a81e17b95b74aa92ec514fa96e2b6316fa785fa"
- name: go-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/go-buildpack-release-1.8.35.1.tgz"
  version: "1.8.35.1"
  sha1: "892149a994765280320e221bba9193bca2c7a664"
- name: java-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/java-buildpack-release-4.19.1.1.tgz"
  version: "4.19.1.1"
  sha1: "325d3bba6cf27a4446ddd5d9f70bd096813522b4"
- name: nodejs-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/nodejs-buildpack-release-1.6.51.1.tgz"
  version: "1.6.51.1"
  sha1: "0a8be0e4c9a1831292cace3638a182557fe11909"
- name: php-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/php-buildpack-release-4.3.77.1.tgz"
  version: "4.3.77.1"
  sha1: "39a85968775afcc4be427cebff676fd14915a984"
- name: python-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/python-buildpack-release-1.6.34.1.tgz"
  version: "1.6.34.1"
  sha1: "4678ec944bcc72ff7eca7396d58b452779381b41"
- name: ruby-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/ruby-buildpack-release-1.7.39.1.tgz"
  version: "1.7.39.1"
  sha1: "ebc40cb5ce2f919770a6eb1de38199e9e2402bc9"
- name: staticfile-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/staticfile-buildpack-release-1.4.42.1.tgz"
  version: "1.4.42.1"
  sha1: "1ab72d15c2002a63de12a5ea7f7469518c19ac29"
- name: nginx-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/nginx-buildpack-release-1.0.12.1.tgz"
  version: "1.0.12.1"
  sha1: "b0919ebffda27c8a0af7f24e25fe037a27eca015"
- name: dotnet-core-buildpack
  url: "https://s3.amazonaws.com/suse-final-releases/dotnet-core-buildpack-release-2.2.12.1.tgz"
  version: "2.2.12.1"
  sha1: "ec0aed04c2b4cee7e1cc516b55a8483f04890d0d"
- name: postgres
  version: "26"
  url: "https://bosh.io/d/github.com/cloudfoundry/postgres-release?v=26"
  sha1: "a436047dae4d4156a1debe9f88bedf59bf40362b"
- name: cf-sle12
  url: "https://s3.amazonaws.com/suse-final-releases/sle12-release-1.75.11.tgz"
  version: "1.75.11"
  sha1: "c9f52bd5f82e82721d65ab5fffdce1ebe7a04eec"
- name: sle15
  url: "https://s3.amazonaws.com/suse-final-releases/sle15-release-4.44.tgz"
  version: "4.44"
  sha1: "ef4a0b017807be2f78ce1728069ba8af0c40ff16"
- name: app-autoscaler
  version: "1.2.1"
  url: "https://bosh.io/d/github.com/cloudfoundry-incubator/app-autoscaler-release?v=1.2.1"
  sha1: "1cc2cd3ed6c7c39f8c984316bb2afb95743ccba1"
- name: cf-usb
  version: "1.0.1"
  url: "https://s3.amazonaws.com/suse-final-releases/cf-usb-release-1.0.1.tgz"
  sha1: "3dc34e90b55d9d61f93f204fce11655b7cd87c87"
- name: groot-btrfs
  url: "https://s3.amazonaws.com/suse-final-releases/groot-btrfs-release-1.0.4.tgz"
  version: "1.0.4"
  sha1: "22381250b0f334d2c5dde04e85a9c1116d8e04fa"
- name: scf-helper
  url: "https://s3.amazonaws.com/suse-final-releases/scf-helper-release-1.0.2.tgz"
  version: "1.0.2"
  sha1: "0f2fb334ad456e35fff7be1fc56edaf2e07e4e26"
- name: "bits-service"
  version: "2.26.0"
  url: "https://bosh.io/d/github.com/cloudfoundry-incubator/bits-service-release?v=2.26.0"
  sha1: "f6a6598fbbac233f94c4a0cfe914970ec34db7b3"
- name: "eirini"
  url: "https://s3.amazonaws.com/suse-final-releases/eirini-release-0.0.6.tgz"
  version: "0.0.6"
  sha1: "6f8ac2c937b8413f833b726e1e578d8c58becb8d"

instance_groups:
- name: eirini
  if_feature: eirini
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: patch-properties
    release: scf-helper
  - name: eirini-persi-broker
    release: eirini
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
            ha: 1
          memory: 256
          virtual-cpus: 2
        ports:
        - name: broker
          protocol: TCP
          internal: 8999
  - name: eirini-extensions
    release: eirini
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
            ha: 1
          memory: 256
          virtual-cpus: 2
        ports:
        - name: webhook
          protocol: TCP
          internal: 2999
  - name: opi
    release: eirini
    properties:
      bosh_containerization:
        run:
          service-account: eirini
          scaling:
            min: 1
            max: 1
            ha: 1
          memory: 256
          virtual-cpus: 2
        ports:
        - name: opi-server
          protocol: TCP
          internal: 8085
- name: bits
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  - scripts/patches/bits_add_missing_config_keys.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: route_registrar
    release: routing
  - name: statsd_injector
    release: statsd-injector
  - name: eirinifs
    release: eirini
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  - name: bits-service
    release: bits-service
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
            ha: 1
          memory: 256
          virtual-cpus: 2
        ports:
        - name: server
          protocol: TCP
          internal: 443
  configuration:
    templates:
      properties.route_registrar.routes: '[{"name":"bits-service","tls_port":443,"uris":["bits.((DOMAIN))", "registry.((DOMAIN))"],"registration_interval":"20s","server_cert_domain_san":"bits","tags":{"component":"bits-service"}}]'
- name: syslog-scheduler
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: scheduler
    release: cf-syslog-drain
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          memory: 128
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - syslog-scheduler
                  topologyKey: "beta.kubernetes.io/os"
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://localhost:8080/health
        ports:
        - name: sched-health
          protocol: TCP
          internal: 8080
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
- name: adapter
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: adapter
    release: cf-syslog-drain
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling: # one per 500 drains
            min: 1
            max: 65535
            ha: 2
          memory: 128
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - adapter
                  topologyKey: "beta.kubernetes.io/os"
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://localhost:8080/health
        ports:
        - name: adapter
          protocol: TCP
          internal: 4443
        - name: adapter-health
          protocol: TCP
          internal: 8080
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
- name: nats
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: nats
    release: nats
    provides:
      nats: {}
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - nats
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: nats
          protocol: TCP
          internal: 4222
        - name: nats-routes
          protocol: TCP
          internal: 4223
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
- name: mysql
  scripts:
  - scripts/create_mysql_data_tmp.sh # Deprecated. Should go away with cf-mysql-release.
  - scripts/chown_vcap_store.sh
  - scripts/pxc/create_directories.sh
  - scripts/patches/fix_mysql_advertise_ip.sh # Deprecated. Should go away with cf-mysql-release.
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: patch-properties
    release: scf-helper
  - name: pxc-mysql
    release: pxc
    provides:
      mysql: {}
    properties:
      bosh_containerization:
        ports:
        - name: pxc-mysql
          protocol: TCP
          internal: 3306
        - name: galera-tcp
          protocol: TCP
          internal: 4567
        - name: galera-agent
          protocol: TCP
          internal: 9200
        run:
          scaling:
            min: 1
            max: 7
            ha: 3
          volumes:
          - path: /var/vcap/store
            type: persistent
            tag: mysql-data
            size: 20
          memory: 2500
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - "[[ $(curl --silent http://${HOSTNAME}:9200/api/v1/status | jq '.healthy') == true ]]"
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - mysql
                  topologyKey: "beta.kubernetes.io/os"
  - name: galera-agent
    release: pxc
  - name: gra-log-purger
    release: pxc
  - name: cluster-health-logger
    release: pxc
  - name: bootstrap
    release: pxc
  - name: mysql
    release: cf-mysql
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  tags:
  - sequential-startup
  configuration:
    templates:
      properties.admin_password: ((MYSQL_ADMIN_PASSWORD))

      # Deprecation start. Should go away with cf-mysql-release. >>
      properties.cf_mysql.mysql.admin_password: ((MYSQL_ADMIN_PASSWORD))
      properties.cf_mysql.mysql.cluster_health.password: ((MYSQL_CLUSTER_HEALTH_PASSWORD))
      properties.cf_mysql.mysql.galera_healthcheck.db_password: ((MYSQL_ADMIN_PASSWORD))
      properties.cf_mysql.mysql.galera_healthcheck.endpoint_password: ((GALERA_HEALTHCHECK_ENDPOINT_DATABASE_PASSWORD))
      # << Deprecation end

      properties.db_password: ((MYSQL_ADMIN_PASSWORD))
      properties.endpoint_password: ((GALERA_HEALTHCHECK_ENDPOINT_DATABASE_PASSWORD))
      properties.engine_config.binlog.enabled: false
      properties.engine_config.galera.enabled: true
      properties.max_open_files: 1500
      properties.monit_startup_timeout: 300
      properties.seeded_databases: '[{"name":"ccdb","password":"((CC_DATABASE_PASSWORD))","username":"ccadmin"},{"name":"diego","password":"((DIEGO_DATABASE_PASSWORD))","username":"diego"},{"name":"routing-api","password":"((ROUTING_API_DATABASE_PASSWORD))","username":"routing-api"},{"name":"usb","username":"usb","password":"((CF_USB_DATABASE_PASSWORD))"},{"name":"nfsvolume","username":"nfsvolume","password":"((PERSI_NFS_DATABASE_PASSWORD))"},{"name":"diego_locket","password":"((LOCKET_DATABASE_PASSWORD))","username":"diego_locket"},{"name":"credhub_user","password":"((CREDHUB_DATABASE_PASSWORD))","username":"credhub_user"}]'
      properties.tls.galera.ca: ((INTERNAL_CA_CERT))
      properties.tls.galera.certificate: ((GALERA_SERVER_CERT))
      properties.tls.galera.private_key: ((GALERA_SERVER_CERT_KEY))
      properties.tls.server.ca: ((INTERNAL_CA_CERT))
      properties.tls.server.certificate: ((MYSQL_SERVER_CERT))
      properties.tls.server.private_key: ((MYSQL_SERVER_CERT_KEY))
- name: mysql-proxy
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: proxy
    release: pxc
    provides:
      proxy: {}
    properties:
      bosh_containerization:
        ports:
        - name: api-proxy
          protocol: TCP
          internal: 8083
        - name: pxc-mysql-proxy
          protocol: TCP
          internal: 3306
        - name: healthck-proxy
          protocol: TCP
          internal: 1936
        run:
          scaling:
            min: 1
            max: 5
            ha: 2
          memory: 2500
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:1936/
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - mysql
                  topologyKey: "beta.kubernetes.io/os"
  - name: route_registrar
    release: routing
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  tags:
  - sequential-startup
  configuration:
    templates:
      properties.api_force_https: false
      properties.api_password: ((CF_MYSQL_PROXY_API_PASSWORD))
      properties.api_port: 8083
      properties.api_uri: mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))((#KUBE_SIZING_MYSQL_COUNT))((/KUBE_SIZING_MYSQL_COUNT))
      properties.api_username: mysql_proxy
      properties.route_registrar.routes: '[{"name":"cf-mysql-proxy","port":8083,"prepend_instance_index":true,"registration_interval":"10s","uris":["mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"]},{"name":"cf-mysql-proxy-aggregator","port":8082,"registration_interval":"10s","uris":["mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"]}]'
- name: cf-usb-group
  default_feature: cf_usb
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: cf-usb
    release: cf-usb
    properties:
      bosh_containerization:
        service_name: cf-usb
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          memory: 128
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - cf-usb
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: usb
          protocol: TCP
          internal: 24054
        - name: usb2
          protocol: TCP
          internal: 24053
  - name: route_registrar
    release: routing
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  tags:
  - sequential-startup
  configuration:
    templates:
      properties.route_registrar.routes: '[{"name":"usb", "port": 24053, "uris":["usb.((DOMAIN))", "*.usb.((DOMAIN))"], "registration_interval":"10s"}, {"name":"broker", "port": 24054, "uris":["brokers.((DOMAIN))", "*.brokers.((DOMAIN))"], "registration_interval":"10s"}]'
- name: diego-api
  unless_feature: eirini
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: bbs
    release: diego
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 2
          active-passive-probe: /var/vcap/jobs/global-properties/bin/readiness/diego-api
          healthcheck:
            readiness:
              command:
              # See BOSH property diego.bbs.health_addr
              - curl --fail http://$(jq -r .health_address /var/vcap/jobs/bbs/config/bbs.json)/ping
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - diego-api
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: cell-bbs-api
          protocol: TCP
          internal: 8889
        - name: cell-bbs-dbg
          protocol: TCP
          internal: 17017
  - name: patch-properties
    release: scf-helper
  - name: cfdot
    release: diego
  tags:
  - active-passive
  - sequential-startup
  configuration:
    templates:
      properties.bbs.hostname: '"diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"' # cfdot property
      properties.diego.bbs.advertisement_base_hostname: ((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
      properties.locket.hostname: '"locket-locket.((KUBERNETES_NAMESPACE))"'    # cfdot property
      properties.tls.ca_certificate: ((INTERNAL_CA_CERT))                   # cfdot property
      properties.tls.certificate: '"((BBS_REP_CERT))"'                      # cfdot property
      properties.tls.private_key: '"((BBS_REP_CERT_KEY))"'                  # cfdot property
- name: locket
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: patch-properties
    release: scf-helper
  - name: locket
    release: diego
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - head -c0 </dev/tcp/${HOSTNAME}/8891
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - locket
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: locket
          protocol: TCP
          internal: 8891
- name: router
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  - name: gorouter
    release: routing
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 65535
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 4
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:8080/health
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - diego-cell
                  topologyKey: "beta.kubernetes.io/os"
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - router
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: router
          protocol: TCP
          external: 80
          internal: 8000
          public: true
        - name: router-ssl
          protocol: TCP
          internal: 443
          public: true
- name: tcp-router
  # XXX haproxy might be able to co-locate with one of the others
  # But this is a _different_ HAProxy from the one in the CF release.
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/patches/fix_haproxy_fd_requirements.sh
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: wait-for-uaa
    release: scf
  - name: tcp_router
    release: routing
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          memory: 128
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:8080/health
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - tcp-router
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: healthcheck
          protocol: TCP
          external: 2341
          internal: 8080
        - name: tcp-route
          protocol: TCP
          internal: 20000-20008
          public: true
          count-configurable: true
          max: 20
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.dns_health_check_host: 'mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)).'
- name: routing-api
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  - name: routing-api
    release: routing
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 4
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - routing-api
                  topologyKey: "beta.kubernetes.io/os"
          # All the routes exposed require UAA auth, so we stick with the TCP healthcheck
          active-passive-probe: head -c0 </dev/tcp/${HOSTNAME}/3000
        ports:
        - name: routing-api
          protocol: TCP
          internal: 3000
  tags:
  - active-passive
  - sequential-startup
  configuration:
    templates:
      properties.dns_health_check_host: 'mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)).'
- name: api-group
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  - scripts/nginx_log_level.sh
  scripts:
  - scripts/patches/fix_blobstore_send_timeout.sh
  - scripts/patches/fix_nodejs_buildpack.sh
  - scripts/forward_logfiles.sh
  - scripts/patches/use_routing_api_private_endpoint.sh
  - scripts/patches/fix_monit_rsyslog.sh
  - scripts/patches/cc_pre_start_home.sh
  - scripts/patches/cc_ng_disable_credhub.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: patch-properties
    release: scf-helper
  - name: cloud_controller_ng
    release: capi
    properties:
      bosh_containerization:
        # XXX Maintain old service name for backwards compatiblities so apps keep running
        service_name: api
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 65535
            ha: 2
          memory: 3800
          virtual-cpus: 4
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:9022/v2/info
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - api-group
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: api
          protocol: TCP
          internal: 9022
        - name: api-tls
          protocol: TCP
          internal: 9023
        - name: api-mutual-tls
          protocol: TCP
          internal: 9024
        - name: statsd
          protocol: TCP
          internal: 8125
  - name: route_registrar
    release: routing
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  - name: statsd_injector
    release: statsd-injector
  - name: go-buildpack
    release: go-buildpack
  - name: binary-buildpack
    release: binary-buildpack
  - name: nodejs-buildpack
    release: nodejs-buildpack
  - name: ruby-buildpack
    release: ruby-buildpack
  - name: php-buildpack
    release: php-buildpack
  - name: python-buildpack
    release: python-buildpack
  - name: staticfile-buildpack
    release: staticfile-buildpack
  - name: nginx-buildpack
    release: nginx-buildpack
  - name: java-buildpack
    release: java-buildpack
  - name: dotnet-core-buildpack
    release: dotnet-core-buildpack
  tags:
  - sequential-startup
  configuration:
    templates:
      properties.route_registrar.routes: '[{"name": "api", "port": 9022, "tls_port": 9024, "server_cert_domain_san": "api-set", "tags": {"component": "CloudController"}, "uris": ["api.((DOMAIN))"], "registration_interval": "10s"}]'
- name: cc-worker
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/cc_worker_disable_credhub.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: cloud_controller_worker
    release: capi
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 65535
            ha: 2
          memory: 750
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - cc-worker
                  topologyKey: "beta.kubernetes.io/os"
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
- name: blobstore
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  scripts:
  - scripts/chown_vcap_store.sh
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_chown_blobstore_packages.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: blobstore
    release: capi
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 1
            # Not HA capable; use external HA storage instead
          volumes:
          - path: /var/vcap/store
            type: persistent
            tag: blobstore-data
            size: 50
          memory: 500
          virtual-cpus: 2
        ports:
        - name: blobstore-ext
          protocol: TCP
          internal: 8080
        - name: blobstore
          protocol: TCP
          internal: 4443
  - name: route_registrar
    release: routing
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.route_registrar.routes: '[{"name":"blobstore", "port":8080, "tags":{"component":"blobstore"}, "uris":["blobstore.((DOMAIN))"], "registration_interval":"10s"}]'
- name: cc-clock
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/cc_clock_disable_credhub.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca
    release: scf
  - name: wait-for-api
    release: scf
    # This job contains a pre-start script whose prupose is to delay
    # pod startup until the API role is up, and thus has run and
    # completed the CC database migrations. If the clock role and job
    # become active while the API role is still doing migrations, or
    # has not even started them yet then the two roles can get into a
    # conflict wrt database access and state which blocks the entire
    # system from coming up.
  - name: cloud_controller_clock
    release: capi
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          memory: 750
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - cc-clock
                  topologyKey: "beta.kubernetes.io/os"
  - name: statsd_injector
    release: statsd-injector
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
- name: log-cache-scheduler
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  - scripts/patches/fix_logcache_certs_scheduler.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: log-cache-scheduler-properties
    release: scf
  - name: log-cache-scheduler
    release: log-cache
    # defaults
  - name: log-cache-expvar-forwarder
    release: log-cache
    # defaults
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 65535
            ha: 2
          memory: 410
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - doppler
                  topologyKey: "beta.kubernetes.io/os"
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.maps: >
        [{ "name": "worker-assignments",
           "source_id": "log-cache-scheduler",
           "addr": "http://localhost:6064/debug/vars",
           "template": "{{.WorkerAssignments | jsonMap}}" },
         { "name": "worker-health",
           "source_id": "log-cache-scheduler",
           "addr": "http://localhost:6064/debug/vars",
           "template": "{{.WorkerHealth | jsonMap}}" }
        ]
      properties.tls.ca_cert: '"((INTERNAL_CA_CERT))"'
      properties.tls.cert: '"((LOG_CACHE_CERT))"'
      properties.tls.key: '"((LOG_CACHE_CERT_KEY))"'
- name: doppler
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: log-cache-gateway
    release: log-cache
    # gateway_addr - default - ":8081"
  - name: log-cache-nozzle
    release: log-cache
    # mostly default, logs_provider cert, see below
  - name: log-cache-cf-auth-proxy
    release: log-cache
  - name: log-cache-expvar-forwarder
    release: log-cache
    # defaults
  - name: log-cache
    release: log-cache
    # certs, see below
    properties:
      bosh_containerization:
        ports:
        - name: log-cache
          protocol: TCP
          internal: 8080
  - name: doppler
    release: loggregator
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 65535
            ha: 2
          memory: 410
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - head -c0 </dev/tcp/${HOSTNAME}/8082
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - doppler
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: dropsonde-udp
          protocol: UDP
          internal: 3457
        - name: dropsonde-tcp
          protocol: TCP
          internal: 3458
        - name: doppler-tls
          protocol: TCP
          internal: 3459
        - name: doppler-ws
          protocol: TCP
          internal: 8081
        - name: doppler-grpc
          protocol: TCP
          internal: 8082
        - name: log-cache-proxy # log-cache-cf-auth-proxy
          protocol: TCP
          internal: 8083
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  - name: route_registrar
    release: routing
  configuration:
    templates:
      properties.cc.ca_cert: '"((INTERNAL_CA_CERT))"'
      properties.cc.common_name: api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
      properties.counters: >
        [{ "name": "egress",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.Egress}}" },
         { "name": "ingress",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.Ingress}}" },
         { "name": "expired",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.Expired}}" },
         { "name": "dropped",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.Dropped}}" },
         { "name": "promql-timeout",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.PromQLTimeout}}" },
         { "name": "egress",
           "source_id": "log-cache-nozzle",
           "addr": "http://localhost:6061/debug/vars",
           "template": "{{.Nozzle.Egress}}" },
         { "name": "ingress",
           "source_id": "log-cache-nozzle",
           "addr": "http://localhost:6061/debug/vars",
           "template": "{{.Nozzle.Ingress}}" },
         { "name": "err",
           "source_id": "log-cache-nozzle",
           "addr": "http://localhost:6061/debug/vars",
           "template": "{{.Nozzle.Err}}" },
         { "name": "dropped",
           "source_id": "log-cache-nozzle",
           "addr": "http://localhost:6061/debug/vars",
           "template": "{{.Nozzle.Dropped}}" }
        ]
      properties.gauges: >
        [{ "name": "cache-period",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.CachePeriod}}" },
         { "name": "store-size",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.StoreSize}}" },
         { "name": "total-system-memory",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.TotalSystemMemory}}" },
         { "name": "available-system-memory",
           "source_id": "log-cache",
           "addr": "http://localhost:6060/debug/vars",
           "template": "{{.LogCache.AvailableSystemMemory}}" },
         { "name": "last-uaa-latency",
           "source_id": "log-cache-cf-auth-proxy",
           "addr": "http://localhost:6065/debug/vars",
           "template": "{{.CFAuthProxy.LastUAALatency}}" },
         { "name": "last-capi-v3-apps-latency",
           "source_id": "log-cache-cf-auth-proxy",
           "addr": "http://localhost:6065/debug/vars",
           "template": "{{.CFAuthProxy.LastCAPIV3AppsLatency}}" },
         { "name": "last-capi-v2-list-service-instances-latency",
           "source_id": "log-cache-cf-auth-proxy",
           "addr": "http://localhost:6065/debug/vars",
           "template": "{{.CFAuthProxy.LastCAPIV2ListServiceInstancesLatency}}" },
         { "name": "last-capi-v4-log-access-latency",
           "source_id": "log-cache-cf-auth-proxy",
           "addr": "http://localhost:6065/debug/vars",
           "template": "{{.CFAuthProxy.LastCAPIV4LogAccessLatency}}" },
         { "name": "last-capi-v2-service-instances-latency",
           "source_id": "log-cache-cf-auth-proxy",
           "addr": "http://localhost:6065/debug/vars",
           "template": "{{.CFAuthProxy.LastCAPIV2ServiceInstancesLatency}}" }
        ]
      properties.logs_provider.tls.ca_cert: '"((INTERNAL_CA_CERT))"'
      properties.logs_provider.tls.cert: '"((LOG_CACHE_CERT))"'
      properties.logs_provider.tls.key: '"((LOG_CACHE_CERT_KEY))"'
      properties.proxy_port: 8083 # log-cache-cf-auth-proxy
      properties.route_registrar.routes: >
        [{ "name": "log-cache-reverse-proxy",
           "tls_port": 8083,
           "server_cert_domain_san": "log-cache",
           "tags": { "component":"log-cache" },
           "uris": ["log-cache.((DOMAIN))", "*.log-cache.((DOMAIN))"],
           "registration_interval": "20s" }
        ]
      properties.tls.ca_cert: '"((INTERNAL_CA_CERT))"'
      properties.tls.cert: '"((LOG_CACHE_CERT))"'
      properties.tls.key: '"((LOG_CACHE_CERT_KEY))"'
      properties.uaa.ca_cert: '"((UAA_CA_CERT))((^UAA_CA_CERT))((INTERNAL_CA_CERT))((/UAA_CA_CERT))"'
      properties.uaa.client_id: 'doppler'
      properties.uaa.client_secret: '"((UAA_CLIENTS_DOPPLER_SECRET))"'
      properties.uaa.internal_addr: '"https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))"'
- name: log-api
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: loggregator_trafficcontroller
    release: loggregator
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 65535
            ha: 2
          memory: 128
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:8081/set-cookie
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - log-api
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: dropsonde
          protocol: TCP
          internal: 8081
  - name: reverse_log_proxy
    release: loggregator
    properties:
      bosh_containerization:
        ports:
        - name: rlp
          protocol: TCP
          internal: 8082
  - name: route_registrar
    release: routing
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.route_registrar.routes: '[{"name":"log-api", "port":8081, "uris":["doppler.((DOMAIN))"], "registration_interval":"10s"}, {"name":"loggregator_trafficcontroller", "port":8080, "uris":["loggregator.((DOMAIN))"], "registration_interval":"10s"}]'
- name: diego-brain
  unless_feature: eirini
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: auctioneer
    release: diego
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 4
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - diego-brain
                  topologyKey: "beta.kubernetes.io/os"
          # Auctioneer has no useful healthcheck routes; we can only use the TCP port
          active-passive-probe: head -c0 </dev/tcp/${HOSTNAME}/9016
        ports:
        - name: diego-auction
          protocol: TCP
          internal: 9016
  - name: patch-properties
    release: scf-helper
  - name: cfdot
    release: diego
  tags:
  - active-passive
  configuration:
    templates:
      properties.bbs.hostname: '"diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"' # cfdot property
      properties.locket.hostname: '"locket-locket.((KUBERNETES_NAMESPACE))"'    # cfdot property
      properties.tls.ca_certificate: ((INTERNAL_CA_CERT))                   # cfdot property
      properties.tls.certificate: '"((BBS_REP_CERT))"'                      # cfdot property
      properties.tls.private_key: '"((BBS_REP_CERT_KEY))"'                  # cfdot property
- name: cc-uploader
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: tps
    release: capi
  - name: cc_uploader
    release: capi
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 4
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - cc-uploader
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: cc-up-listen
          protocol: TCP
          internal: 9091
        - name: cc-up-dbg
          protocol: TCP
          internal: 17018
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
- name: diego-ssh
  unless_feature: eirini
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: ssh_proxy
    release: diego
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          capabilities: [SYS_RESOURCE]
          memory: 128
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:8080/v1/static/file_server/bin/file-server
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - diego-ssh
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: diego-ssh
          protocol: TCP
          internal: 2222
          public: true
  - name: file_server
    release: diego
    properties:
      bosh_containerization:
        # XXX Maintain old service name so DesiredLRPs remain valid after upgrades
        service_name: diego-access
        ports:
        - name: diego-files
          protocol: TCP
          internal: 8080
- name: nfs-broker
  unless_feature: eirini
  environment_scripts:
  - scripts/go_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  - scripts/patches/nfsbroker_cert_prop.sh
  - scripts/patches/nfsbroker_ctl.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: nfsbroker
    release: nfs-volume
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          privileged: true
          memory: 128
          virtual-cpus: 2
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - nfs-broker
                  topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: nfsbroker
          protocol: TCP
          internal: 8999
  tags:
  - sequential-startup
  configuration:
    templates:
      properties.nfsbroker.credhub.ca_cert: '~'
      properties.nfsbroker.credhub.uaa_ca_cert: '~'
      properties.nfsbroker.db_ca_cert: '~'
- name: diego-cell
  unless_feature: eirini
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  - scripts/set-diego-cell-memory-limits.sh
  - scripts/go_log_level.sh
  - scripts/configure-garden-filesystem.sh
  - scripts/configure-az.sh
  - scripts/configure-pz.sh
  scripts:
  - scripts/check_swapaccounting.sh
  - scripts/configure-nested-net.sh
  - scripts/cleanup-garden-graph.sh
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  - scripts/patches/mapfs_pre_start.sh
  - scripts/patches/nfs-volume-nfsv3driver-libdir.sh
  - scripts/patches/fix_garden_logdir.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: get-kubectl
    release: scf
  - name: wait-for-uaa
    release: scf
  - name: rep
    release: diego
    properties:
      bosh_containerization:
        ports:
        - name: rep-server
          protocol: TCP
          internal: 1801
  - name: patch-properties
    release: scf-helper
  - name: cfdot
    release: diego
  - name: route_emitter
    release: diego
  - name: garden
    release: garden-runc
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        # Instance group needs volume claim templates (see storage below), no LB => clustered
        run:
          scaling:
            min: 1
            max: 254
            # Not sure why 2 isn't enough for HA, but https://docs.cloudfoundry.org/concepts/high-availability.html disagrees
            ha: 3
          privileged: true
          service-account: garden-runc
          volumes:
          - path: /var/vcap/data/grootfs
            type: persistent
            tag: grootfs-data
            size: 50
          - path: /sys/fs/cgroup
            type: host
            tag: host-cgroup
          memory: 2800
          virtual-cpus: 4
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - diego-cell
                  topologyKey: "beta.kubernetes.io/os"
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: "app.kubernetes.io/component"
                      operator: In
                      values:
                      - router
                  topologyKey: "beta.kubernetes.io/os"
  - name: groot-btrfs
    release: groot-btrfs
  - name: cflinuxfs2-rootfs-setup
    release: cflinuxfs2
  - name: cflinuxfs3-rootfs-setup
    release: cflinuxfs3
  - name: cf-sle12-setup
    release: cf-sle12
  - name: sle15-rootfs-setup
    release: sle15
  - name: nfsv3driver
    release: nfs-volume
    properties:
      bosh_containerization:
        ports:
        - name: nfs-driver
          protocol: TCP
          internal: 7589
        - name: nfs-admin
          protocol: TCP
          internal: 7590
  - name: mapfs
    release: mapfs
  configuration:
    templates:
      properties.bbs.hostname: '"diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"' # cfdot property
      properties.containers.trusted_ca_certificates: "[((#TRUSTED_CERTS))((TRUSTED_CERTS)),((/TRUSTED_CERTS))((INTERNAL_CA_CERT))]"
      properties.diego.rep.advertise_domain: diego-cell-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
      properties.locket.hostname: '"locket-locket.((KUBERNETES_NAMESPACE))"'    # cfdot property
      properties.tls.ca_cert: ((INTERNAL_CA_CERT))
      properties.tls.ca_certificate: ((INTERNAL_CA_CERT))                   # cfdot property
      properties.tls.cert: ((REP_SERVER_CERT))
      properties.tls.certificate: '"((BBS_REP_CERT))"'                      # cfdot property
      properties.tls.key: ((REP_SERVER_CERT_KEY))
      properties.tls.private_key: '"((BBS_REP_CERT_KEY))"'                  # cfdot property
- name: acceptance-tests-brain
  type: bosh-task
  tags:
  - stop-on-failure
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: acceptance-tests-brain
    release: scf
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
          flight-stage: manual
          service-account: tests-brain
- name: acceptance-tests
  type: bosh-task
  tags:
  - stop-on-failure
  scripts:
  - scripts/cf_acceptance_tests_suites.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: acceptance-tests
    release: scf
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
          flight-stage: manual
  configuration:
    templates:
      properties.acceptance_tests.nodes: '"((ACCEPTANCE_TEST_NODES))"'
      scf.cats-suites: '"((CATS_SUITES))"'
- name: sync-integration-tests
  type: bosh-task
  tags:
  - stop-on-failure
  jobs:
  - name: global-properties # This needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca
    release: scf
  - name: sync-integration-tests
    release: scf
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 0
            max: 1
          flight-stage: manual
          service-account: tests-sits
  configuration:
    templates:
      properties.sync_integration_tests.bbs.svc.name: diego-api-bbs
      properties.sync_integration_tests.bbs.svc.namespace: ((KUBERNETES_NAMESPACE))
      properties.sync_integration_tests.bbs.svc.port: 8889
      properties.sync_integration_tests.config.bbs_client_cert_contents: '"((BBS_CLIENT_CRT))"'
      properties.sync_integration_tests.config.bbs_client_key_contents: '"((BBS_CLIENT_CRT_KEY))"'
      properties.sync_integration_tests.config.cf_admin_password: '"((CLUSTER_ADMIN_PASSWORD))"((#INTERNAL_CA_CERT_KEY))((/INTERNAL_CA_CERT_KEY))'
      properties.sync_integration_tests.config.cf_api: api.((DOMAIN))
      properties.sync_integration_tests.config.cf_apps_domain: ((DOMAIN))
      properties.sync_integration_tests.setup.focus: "'((SYNC_INTEGRATION_TESTS_FOCUS))'"
      properties.sync_integration_tests.setup.nodes: "'((SYNC_INTEGRATION_TESTS_NODES))'"
      properties.sync_integration_tests.setup.skip: "'((SYNC_INTEGRATION_TESTS_SKIP))'"
      properties.sync_integration_tests.setup.verbose: "'((SYNC_INTEGRATION_TESTS_VERBOSE))'"
- name: smoke-tests
  type: bosh-task
  tags:
  - stop-on-failure
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: cf-cli-6-linux
    release: cf-cli
  - name: smoke_tests
    release: cf-smoke-tests
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
          flight-stage: manual
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.smoke_tests.client_secret: ((UAA_CLIENTS_CF_SMOKE_TESTS_CLIENT_SECRET))
- name: secret-generation
  type: bosh-task
  jobs:
  - name: generate-secrets
    release: scf-helper
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
          flight-stage: pre-flight
          memory: 256
          virtual-cpus: 1
          service-account: secret-generator
  configuration:
    templates:
      properties.scf.secrets.cert_expiration: ((CERT_EXPIRATION))
      properties.scf.secrets.cluster_domain: ((KUBERNETES_CLUSTER_DOMAIN))
      properties.scf.secrets.domain: ((DOMAIN))
      properties.scf.secrets.generation: ((KUBE_SECRETS_GENERATION_COUNTER))
      properties.scf.secrets.is_install: ((HELM_IS_INSTALL))
      properties.scf.secrets.name: ((KUBE_SECRETS_GENERATION_NAME))
      properties.scf.secrets.namespace: ((KUBERNETES_NAMESPACE))
- name: post-deployment-setup
  type: bosh-task
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: uaa-create-user
    release: scf
  - name: configure-scf
    release: scf
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
          flight-stage: post-flight
          memory: 256
          virtual-cpus: 1
          service-account: eirini
- name: credhub-user
  if_feature: credhub
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  - scripts/credhub_log_level.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: credhub
    release: credhub
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 1
            ha: 1
          persistent-volumes: []
          shared-volumes: []
          memory: 2000
          virtual-cpus: 2
          healthcheck:
            readiness:
        ports:
        - name: api #apiserverport
          protocol: TCP
          external: 8844
          internal: 8844
  - name: route_registrar
    release: routing
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.credhub.authentication.uaa.ca_certs: '["((UAA_CA_CERT))"]'
      properties.credhub.authentication.uaa.internal_url: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))
      properties.credhub.authentication.uaa.url: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))
      properties.credhub.authorization.acls.enabled: false
      properties.credhub.data_storage.database: "credhub_user"
      properties.credhub.data_storage.host: mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
      properties.credhub.data_storage.password: ((CREDHUB_DATABASE_PASSWORD))
      properties.credhub.data_storage.port: 3306
      properties.credhub.data_storage.require_tls: false
      properties.credhub.data_storage.tls_ca: ((INTERNAL_CA_CERT))
      properties.credhub.data_storage.type: "mysql"
      properties.credhub.data_storage.username: "credhub_user"
      properties.credhub.encryption.keys: '[{"provider_name":"internal-provider", "active":true, "key_properties":{"encryption_password":"((CREDHUB_ENCRYPT_KEY))"}}]'
      properties.credhub.encryption.providers: '[{"name":"internal-provider", "type":"internal"}]'
      properties.credhub.log_level: '"((CREDHUB_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
      properties.credhub.tls: '{"certificate":"((CREDHUB_SERVER_CERT))","private_key":"((CREDHUB_SERVER_CERT_KEY))"}'
      properties.route_registrar.routes: '[{"name":"credhub", "tls_port":8844, "server_cert_domain_san":"credhub-set", "tags":{"component":"credhub"}, "uris":["credhub.((DOMAIN))"], "registration_interval":"10s"}]'
- name: autoscaler-postgres
  if_feature: autoscaler
  scripts:
  - scripts/chown_vcap_store.sh
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  - scripts/patches/fix_postgres_prestart.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: postgres
    release: postgres
    properties:
      bosh_containerization:
        run:
          scaling:
            # The postgres-release BOSH release currently does not support HA; limit this to one replica.
            # https://github.com/cloudfoundry/postgres-release#known-limitations
            min: 1
            max: 1
            ha: 1
          volumes:
          - path: /var/vcap/store
            type: persistent
            tag: postgres-data
            size: 5
          memory: 1024
          virtual-cpus: 2
        ports:
        - name: postgres
          protocol: TCP
          external: 5432
          internal: 5432
  configuration:
    templates:
      properties.databases.databases: '[{"name":"autoscaler","tag":"default"}]'
      properties.databases.port: '"((AUTOSCALER_DB_PORT))"'
      properties.databases.roles: '[{"name": "((AUTOSCALER_DB_ROLE_NAME))", "password": "((AUTOSCALER_DB_PASSWORD))", "tag": "default"}]' 
- name: autoscaler-api
  if_feature: autoscaler
  environment_scripts:
  - scripts/configure-HA-hosts.sh
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: apiserver
    release: app-autoscaler
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          memory: 256
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:9101
          affinity:
           podAntiAffinity:
             preferredDuringSchedulingIgnoredDuringExecution:
             - weight: 100
               podAffinityTerm:
                 labelSelector:
                   matchExpressions:
                   - key: "app.kubernetes.io/component"
                     operator: In
                     values:
                     - autoscaler-api
                 topologyKey: "beta.kubernetes.io/os"
        ports:
        - name: api  # apiserverport
          protocol: TCP
          external: 7100
          internal: 7100
        - name: apihealthport
          protocol: TCP
          external: 9101
          internal: 9101
  - name: route_registrar
    release: routing
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.route_registrar.routes: '[{"name":"autoscalerapiserver", "port":7106, "tags":{"component":"autoscalerapiserver"}, "uris":["autoscaler.((DOMAIN))"], "registration_interval":"10s"}]'
- name: autoscaler-metrics
  if_feature: autoscaler
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: metricscollector
    release: app-autoscaler
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          memory: 1024
          virtual-cpus: 4
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:9103
              - curl --silent --fail --head http://${HOSTNAME}:9105          
          affinity:
           podAntiAffinity:
             preferredDuringSchedulingIgnoredDuringExecution:
             - weight: 100
               podAffinityTerm:
                 labelSelector:
                   matchExpressions:
                   - key: "app.kubernetes.io/component"
                     operator: In
                     values:
                     - autoscaler-metrics
                 topologyKey: "beta.kubernetes.io/os"           
        ports:
        - name: metrics  # metricscollectorport
          protocol: TCP
          external: 7103
          internal: 7103
        - name: mchealthport
          protocol: TCP
          external: 9103
          internal: 9103  
  - name: eventgenerator
    release: app-autoscaler
    properties:
      bosh_containerization:    
        ports:
        - name: eventgen  # eventgeneratorport
          protocol: TCP
          external: 7105
          internal: 7105
        - name: eghealthport
          protocol: TCP
          external: 9105
          internal: 9105
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
- name: autoscaler-actors
  if_feature: autoscaler
  scripts:
  - scripts/forward_logfiles.sh
  - scripts/patches/fix_monit_rsyslog.sh
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: authorize-internal-ca # needs to be second as it is a dependency of other jobs.
    release: scf
  - name: scheduler
    release: app-autoscaler
    properties:
      bosh_containerization:
        colocated_containers:
        - loggregator-agent
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
          memory: 2350
          virtual-cpus: 2
          healthcheck:
            readiness:
              command:
              - curl --silent --fail --head http://${HOSTNAME}:9102
              - curl --silent --fail --head http://${HOSTNAME}:9104
              - curl --silent --fail --head http://${HOSTNAME}:9108          
          affinity:
           podAntiAffinity:
             preferredDuringSchedulingIgnoredDuringExecution:
             - weight: 100
               podAffinityTerm:
                 labelSelector:
                   matchExpressions:
                   - key: "app.kubernetes.io/component"
                     operator: In
                     values:
                     - autoscaler-actors
                 topologyKey: "beta.kubernetes.io/os"           
        ports:
        - name: scheduler  # schedulerport
          protocol: TCP
          external: 7102
          internal: 7102
        - name: sdhealthport
          protocol: TCP
          external: 9102
          internal: 9102
  - name: scalingengine
    release: app-autoscaler
    properties:
      bosh_containerization:      
        ports:
        - name: scaling-engine  # scalingengineport
          protocol: TCP
          external: 7104
          internal: 7104
        - name: sehealthport
          protocol: TCP
          external: 9104
          internal: 9104          
  - name: operator
    release: app-autoscaler
    properties:
      bosh_containerization:
        ports:
        - name: ophealthport
          protocol: TCP
          external: 9108
          internal: 9108
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true                    
- name: loggregator-agent
  type: colocated-container
  post_config_scripts:
  - scripts/bpm_kube_dns.rb
  jobs:
  - name: global-properties # needs to be first so images use it for processing monit templates.
    release: scf-helper
  - name: loggr-expvar-forwarder
    release: loggregator-agent
  - name: loggregator_agent
    release: loggregator-agent
    properties:
      bosh_containerization:
        run:
          scaling:
            min: 1
            max: 3
            ha: 2
  - name: bpm
    release: bpm
    properties:
      bosh_containerization:
        run:
          privileged: true
  configuration:
    templates:
      properties.counters: >
        [{ "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "dropped",
           "template": "{{.Agent.Dropped}}" },
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "dropped",
           "template": "{{.Agent.DroppedEgressV2}}",
           "tags": {
             "direction": "egress",
             "metric_version": "2.0" }},
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "dropped",
           "template": "{{.Agent.DroppedIngressV2}}",
           "tags": {
             "direction": "ingress",
             "metric_version": "2.0" }},
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "egress",
           "template": "{{.Agent.Egress}}" },
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "egress",
           "template": "{{.Agent.EgressV2}}",
           "tags": {
             "metric_version": "2.0" }},
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "ingress",
           "template": "{{.Agent.Ingress}}" },
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "ingress",
           "template": "{{.Agent.IngressV2}}",
           "tags": {
             "metric_version": "2.0" }}
        ]
      properties.default_source_id: 'metron'
      properties.fissile.monit.port: 2290
      properties.gauges: >
        [{ "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "average_envelopes",
           "unit": "bytes/minute",
           "template": "{{.Agent.AverageEnvelope}}",
           "tags": {
             "loggregator": "v1" }},
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "average_envelopes",
           "unit": "bytes/minute",
           "template": "{{.Agent.AverageEnvelopeV2}}",
           "tags": {
             "metric_version": "2.0",
             "loggregator": "v2" }},
         { "addr": "http://127.0.0.1:14824/debug/vars",
           "name": "origin_mappings",
           "unit": "bytes/minute",
           "template": "{{.Agent.OriginMappingsV2}}",
           "tags": {
             "metric_version": "2.0" }}
        ]
      properties.log_agent.ca_cert: ((INTERNAL_CA_CERT))
      properties.log_agent.client_cert: '"((LOGGREGATOR_FORWARD_CERT))"'
      properties.log_agent.client_key: '"((LOGGREGATOR_FORWARD_CERT_KEY))"'
configuration:
  auth:
    roles:
      configgin-role:
      - apiGroups: [""]
        resources: [pods]
        verbs: [get, list, patch]
      - apiGroups: [""]
        resources: [services]
        verbs: [get]
      - apiGroups: [apps]
        resources: [statefulsets]
        verbs: [get, patch]
      psp-role:
      - apiGroups: [extensions]
        resourceNames: [default]
        resources: [podsecuritypolicies]
        verbs: [use]
      secrets-role:
      - apiGroups: [""]
        resources: [configmaps, secrets]
        verbs: [create, get, list, patch, update, delete]
      test-role-brain:
      - apiGroups: [""]
        resources: [services]
        verbs: [create, get, delete]
      - apiGroups: [extensions]
        resources: [replicasets]
        verbs: [create, get, list, delete, update]
      - apiGroups: [apps]
        resources: [statefulsets]
        verbs: [create, get, update, delete, list]
      - apiGroups: [""]
        resources: ["pods"]
        verbs: [create, get, list, delete, update]
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: [create, delete]
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: [create, delete, get, list]
      - apiGroups: [""]
        resources: ["secrets"]
        verbs: [get, list]
      test-role-sits:
      - apiGroups: [""]
        resources: [pods/portforward]
        verbs: [create]
    cluster-roles:
      node-reader-role:
      - apiGroups: [""]
        resources: [nodes]
        verbs: [get, list, watch]
      eirini-role:
      - apiGroups: ["*"]
        resources: ["*"]
        verbs: ["*"]
      test-cluster-role:
      - apiGroups: [""]
        resources: [namespaces]
        verbs: [create, get, delete]
      - apiGroups: [""]
        resources: [pods, pods/log]
        verbs: [get, list, watch]
      - apiGroups: [""]
        resources: [pods/portforward]
        verbs: [create]
      - apiGroups: ["rbac.authorization.k8s.io"]
        resources: [clusterrolebindings]
        verbs: [delete]
      - apiGroups: [""]
        resources: [persistentvolumes, persistentvolumeclaims]
        verbs: [get, list]
      - apiGroups: [storage.k8s.io]
        resources: [storageclasses]
        verbs: [get, list]
    pod-security-policies:
      default:
        allowPrivilegeEscalation: true
        allowedCapabilities: ["*"]
        defaultAllowPrivilegeEscalation: true
        fsGroup: { rule: RunAsAny }
        hostPorts: [{ min: 0, max: 65535 }]
        privileged: true
        runAsUser: { rule: RunAsAny }
        seLinux: { rule: RunAsAny }
        supplementalGroups: { rule: RunAsAny }
        volumes:
        - configMap
        - secret
        - emptyDir
        - downwardAPI
        - projected
        - persistentVolumeClaim
        - nfs
    accounts:
      default:
        roles: [configgin-role, psp-role]
      secret-generator:
        roles: [configgin-role, secrets-role, psp-role]
      tests-brain:
        roles: [configgin-role, test-role-brain, psp-role]
        cluster-roles: [test-cluster-role]
      tests-sits:
        roles: [configgin-role, test-role-sits, psp-role]
      garden-runc:
        roles: [configgin-role, psp-role]
        cluster-roles: [node-reader-role]
      eirini:
        roles: [configgin-role]
        cluster-roles: [eirini-role]
  templates:
    az: '"((KUBE_AZ))"'
    id: ((HOSTNAME))
    index: ((KUBE_COMPONENT_INDEX))((^KUBE_COMPONENT_INDEX))0((/KUBE_COMPONENT_INDEX))
    ip: '"((IP_ADDRESS))"'
    networks.default.dns_record_name: '"((DNS_RECORD_NAME))"'
    networks.default.ip: '"((IP_ADDRESS))"'
    # We include INTERNAL_CA_CERT_KEY here so validation doesn't complain that it's not being used.
    # we can't make it internal, as that exposes it everywhere. The acceptance tests are not used at runtime so it's safe.
    properties.acceptance_tests.admin_password: '"((CLUSTER_ADMIN_PASSWORD))"((#INTERNAL_CA_CERT_KEY))((/INTERNAL_CA_CERT_KEY))'
    properties.acceptance_tests.api: '"api.((DOMAIN))"'
    properties.acceptance_tests.apps_domain: '"((DOMAIN))"'
    properties.acceptance_tests_brain.domain: '"((DOMAIN))"'
    properties.acceptance_tests_brain.namespace: '"((KUBERNETES_NAMESPACE))"'
    properties.acceptance_tests_brain.password: '"((CLUSTER_ADMIN_PASSWORD))"'
    properties.acceptance_tests_brain.storage_class: '"((KUBERNETES_STORAGE_CLASS_PERSISTENT))"'
    properties.acceptance_tests_brain.tcp_domain: '"((TCP_DOMAIN))"'
    properties.app_domains: '["((DOMAIN))"]'
    properties.app_ssh.host_key_fingerprint: '"((APP_SSH_KEY_FINGERPRINT))"'
    properties.autoscaler.api_server.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.api_server.eventgenerator.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.api_server.eventgenerator.client_cert: '"((AUTOSCALER_ASMETRICS_CLIENT_CERT))"'
    properties.autoscaler.api_server.eventgenerator.client_key: '"((AUTOSCALER_ASMETRICS_CLIENT_CERT_KEY))"'
    properties.autoscaler.api_server.eventgenerator.host: '"autoscaler-metrics-eventgenerator.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.autoscaler.api_server.metrics_collector.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.api_server.metrics_collector.client_cert: '"((AUTOSCALER_ASMETRICS_CLIENT_CERT))"'
    properties.autoscaler.api_server.metrics_collector.client_key: '"((AUTOSCALER_ASMETRICS_CLIENT_CERT_KEY))"'
    properties.autoscaler.api_server.metrics_collector.host: '"autoscaler-metrics-metricscollector.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.autoscaler.api_server.public_ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.api_server.public_server_cert: '"((AUTOSCALER_ASAPI_PUBLIC_SERVER_CERT))"'
    properties.autoscaler.api_server.public_server_key: '"((AUTOSCALER_ASAPI_PUBLIC_SERVER_CERT_KEY))"'
    properties.autoscaler.api_server.scaling_engine.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.api_server.scaling_engine.client_cert: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT))"'
    properties.autoscaler.api_server.scaling_engine.client_key: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT_KEY))"'
    properties.autoscaler.api_server.scaling_engine.host: '"autoscaler-actors-scalingengine.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.autoscaler.api_server.scheduler.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.api_server.scheduler.client_cert: '"((AUTOSCALER_SCHEDULER_CLIENT_CERT))"'
    properties.autoscaler.api_server.scheduler.client_key: '"((AUTOSCALER_SCHEDULER_CLIENT_CERT_KEY))"'
    properties.autoscaler.api_server.scheduler.host: '"autoscaler-actors-scheduler.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.autoscaler.api_server.server_cert: '"((AUTOSCALER_ASAPI_SERVER_CERT))"'
    properties.autoscaler.api_server.server_key: '"((AUTOSCALER_ASAPI_SERVER_CERT_KEY))"'
    properties.autoscaler.appmetrics_db.address: '((AUTOSCALER_DB_ADDRESS))'
    properties.autoscaler.appmetrics_db.port: '"((AUTOSCALER_DB_PORT))"'
    properties.autoscaler.appmetrics_db.roles: '[{"name": "((AUTOSCALER_DB_ROLE_NAME))", "password": "((AUTOSCALER_DB_PASSWORD))", "tag": "default"}]'
    properties.autoscaler.cf.api: '"https://api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):9024"'
    properties.autoscaler.cf.secret: '"((AUTOSCALER_UAA_CLIENT_SECRET))"'
    properties.autoscaler.eventgenerator.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.eventgenerator.metricscollector.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.eventgenerator.metricscollector.client_cert: '"((AUTOSCALER_ASMETRICS_CLIENT_CERT))"'
    properties.autoscaler.eventgenerator.metricscollector.client_key: '"((AUTOSCALER_ASMETRICS_CLIENT_CERT_KEY))"'
    properties.autoscaler.eventgenerator.scaling_engine.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.eventgenerator.scaling_engine.client_cert: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT))"'
    properties.autoscaler.eventgenerator.scaling_engine.client_key: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT_KEY))"'
    properties.autoscaler.eventgenerator.scaling_engine.host: '"autoscaler-actors-scalingengine.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.autoscaler.eventgenerator.server_cert: '"((AUTOSCALER_ASMETRICS_SERVER_CERT))"'
    properties.autoscaler.eventgenerator.server_key: '"((AUTOSCALER_ASMETRICS_SERVER_CERT_KEY))"'
    properties.autoscaler.instancemetrics_db.address: '((AUTOSCALER_DB_ADDRESS))'
    properties.autoscaler.instancemetrics_db.port: '"((AUTOSCALER_DB_PORT))"'
    properties.autoscaler.instancemetrics_db.roles: '[{"name": "((AUTOSCALER_DB_ROLE_NAME))", "password": "((AUTOSCALER_DB_PASSWORD))", "tag": "default"}]'
    properties.autoscaler.lock_db.address: '((AUTOSCALER_DB_ADDRESS))'
    properties.autoscaler.lock_db.port: '"((AUTOSCALER_DB_PORT))"'
    properties.autoscaler.lock_db.roles: '[{"name": "((AUTOSCALER_DB_ROLE_NAME))", "password": "((AUTOSCALER_DB_PASSWORD))", "tag": "default"}]'
    properties.autoscaler.metricscollector.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.metricscollector.server_cert: '"((AUTOSCALER_ASMETRICS_SERVER_CERT))"'
    properties.autoscaler.metricscollector.server_key: '"((AUTOSCALER_ASMETRICS_SERVER_CERT_KEY))"'
    properties.autoscaler.operator.scaling_engine.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.operator.scaling_engine.client_cert: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT))"'
    properties.autoscaler.operator.scaling_engine.client_key: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT_KEY))"'
    properties.autoscaler.operator.scheduler.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.operator.scheduler.client_cert: '"((AUTOSCALER_SCHEDULER_CLIENT_CERT))"'
    properties.autoscaler.operator.scheduler.client_key: '"((AUTOSCALER_SCHEDULER_CLIENT_CERT_KEY))"'
    properties.autoscaler.policy_db.address: '((AUTOSCALER_DB_ADDRESS))'
    properties.autoscaler.policy_db.port: '"((AUTOSCALER_DB_PORT))"'
    properties.autoscaler.policy_db.roles: '[{"name": "((AUTOSCALER_DB_ROLE_NAME))", "password": "((AUTOSCALER_DB_PASSWORD))", "tag": "default"}]'
    properties.autoscaler.scalingengine.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.scalingengine.server_cert: '"((AUTOSCALER_SCALING_ENGINE_SERVER_CERT))"'
    properties.autoscaler.scalingengine.server_key: '"((AUTOSCALER_SCALING_ENGINE_SERVER_CERT_KEY))"'
    properties.autoscaler.scalingengine_db.address: '((AUTOSCALER_DB_ADDRESS))'
    properties.autoscaler.scalingengine_db.port: '"((AUTOSCALER_DB_PORT))"'    
    properties.autoscaler.scalingengine_db.roles: '[{"name": "((AUTOSCALER_DB_ROLE_NAME))", "password": "((AUTOSCALER_DB_PASSWORD))", "tag": "default"}]'
    properties.autoscaler.scheduler.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.scheduler.scaling_engine.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.autoscaler.scheduler.scaling_engine.client_cert: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT))"'
    properties.autoscaler.scheduler.scaling_engine.client_key: '"((AUTOSCALER_SCALING_ENGINE_CLIENT_CERT_KEY))"'
    properties.autoscaler.scheduler.server_cert: '"((AUTOSCALER_SCHEDULER_SERVER_CERT))"'
    properties.autoscaler.scheduler.server_key: '"((AUTOSCALER_SCHEDULER_SERVER_CERT_KEY))"'
    properties.autoscaler.scheduler_db.address: '((AUTOSCALER_DB_ADDRESS))'
    properties.autoscaler.scheduler_db.port: '"((AUTOSCALER_DB_PORT))"'
    properties.autoscaler.scheduler_db.roles: '[{"name": "((AUTOSCALER_DB_ROLE_NAME))", "password": "((AUTOSCALER_DB_PASSWORD))", "tag": "default"}]'
    properties.bits-service.active_signing_key.secret: "((BITS_SERVICE_SECRET))"
    properties.bits-service.app_stash.webdav_config.ca_cert: "((INTERNAL_CA_CERT))"
    properties.bits-service.app_stash.webdav_config.password: "((BLOBSTORE_PASSWORD))"
    properties.bits-service.app_stash.webdav_config.private_endpoint: "https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443"
    properties.bits-service.app_stash.webdav_config.public_endpoint: "https://blobstore.((DOMAIN))"
    properties.bits-service.buildpacks.webdav_config.ca_cert: ((INTERNAL_CA_CERT))
    properties.bits-service.buildpacks.webdav_config.password: ((BLOBSTORE_PASSWORD))
    properties.bits-service.buildpacks.webdav_config.private_endpoint: "https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443"
    properties.bits-service.buildpacks.webdav_config.public_endpoint: "https://blobstore.((DOMAIN))"
    properties.bits-service.cc_updates.ca_cert: ((INTERNAL_CA_CERT))
    properties.bits-service.cc_updates.cc_url: "https://api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):9024/internal/v4/packages"
    properties.bits-service.cc_updates.client_cert: ((CC_PUBLIC_TLS_CERT))
    properties.bits-service.cc_updates.client_key: ((CC_PUBLIC_TLS_CERT_KEY))
    properties.bits-service.droplets.webdav_config.ca_cert: ((INTERNAL_CA_CERT))
    properties.bits-service.droplets.webdav_config.password: ((BLOBSTORE_PASSWORD))
    properties.bits-service.droplets.webdav_config.private_endpoint: "https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443"
    properties.bits-service.droplets.webdav_config.public_endpoint: "https://blobstore.((DOMAIN))"
    properties.bits-service.packages.webdav_config.ca_cert: ((INTERNAL_CA_CERT))
    properties.bits-service.packages.webdav_config.password: ((BLOBSTORE_PASSWORD))
    properties.bits-service.packages.webdav_config.private_endpoint: "https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443"
    properties.bits-service.packages.webdav_config.public_endpoint: https://blobstore.((DOMAIN))
    properties.bits-service.private_endpoint: "https://bits-bits-service.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"
    properties.bits-service.public_endpoint: "https://bits.((DOMAIN))"
    properties.bits-service.signing_users: '[{"username": "admin", "password": "((BITS_ADMIN_USERS_PASSWORD))"}]'
    properties.bits-service.tls.cert: ((BITS_SERVICE_SSL_CERT))
    properties.bits-service.tls.key: ((BITS_SERVICE_SSL_CERT_KEY))
    properties.blobstore.admin_users: '[{"username": "blobstore_user", "password": "((BLOBSTORE_PASSWORD))"}]'
    properties.blobstore.internal_access_rules: '[((BLOBSTORE_ACCESS_RULES))]'
    properties.blobstore.max_upload_size: ((BLOBSTORE_MAX_UPLOAD_SIZE))m
    properties.blobstore.secure_link.secret: '"((BLOBSTORE_SECURE_LINK))"'
    properties.blobstore.tls.cert: '"((BLOBSTORE_TLS_CERT))"'
    properties.blobstore.tls.private_key: '"((BLOBSTORE_TLS_CERT_KEY))"'
    properties.build: '"((CLUSTER_BUILD))"'
    properties.capi.cc_uploader.cc.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.capi.cc_uploader.cc.client_cert: '"((CC_SERVER_CRT))"'
    properties.capi.cc_uploader.cc.client_key: '"((CC_SERVER_CRT_KEY))"'
    properties.capi.cc_uploader.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.capi.cc_uploader.mutual_tls.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.capi.cc_uploader.mutual_tls.server_cert: '"((CC_UPLOADER_CRT))"'
    properties.capi.cc_uploader.mutual_tls.server_key: '"((CC_UPLOADER_CRT_KEY))"'
    properties.capi.tps.bbs.api_location: diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8889
    properties.capi.tps.bbs.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.capi.tps.bbs.client_cert: '"((BBS_CLIENT_CRT))"'
    properties.capi.tps.bbs.client_key: '"((BBS_CLIENT_CRT_KEY))"'
    properties.capi.tps.cc.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.capi.tps.cc.client_cert: '"((TPS_CC_CLIENT_CRT))"'
    properties.capi.tps.cc.client_key: '"((TPS_CC_CLIENT_CRT_KEY))"'
    properties.capi.tps.cc.internal_service_hostname: api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
    properties.capi.tps.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.capi.tps.traffic_controller_url: ws://log-api-loggregator-trafficcontroller.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8081
    properties.capi.tps.watcher.locket.api_location: '"locket-locket.((KUBERNETES_NAMESPACE)):8891"'
    properties.cc.allow_app_ssh_access: ((ALLOW_APP_SSH_ACCESS))
    properties.cc.allowed_cors_domains: ((ALLOWED_CORS_DOMAINS))
    properties.cc.app_bits_max_body_size: ((NGINX_MAX_REQUEST_BODY_SIZE))M
    properties.cc.app_bits_upload_grace_period_in_seconds: ((APP_TOKEN_UPLOAD_GRACE_PERIOD))

    properties.cc.bits_service.ca_cert: "((INTERNAL_CA_CERT))"
    properties.cc.bits_service.password: "((BITS_ADMIN_USERS_PASSWORD))"
    properties.cc.bits_service.private_endpoint: "https://bits-bits-service.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"
    properties.cc.bits_service.public_endpoint: "https://bits.((DOMAIN))"

    properties.cc.broker_client_timeout_seconds: '"((BROKER_CLIENT_TIMEOUT_SECONDS))"'
    properties.cc.buildpacks.cdn.uri: '"((CDN_URI))"'
    properties.cc.buildpacks.webdav_config.password: '"((BLOBSTORE_PASSWORD))"'
    properties.cc.buildpacks.webdav_config.private_endpoint: https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443
    properties.cc.buildpacks.webdav_config.public_endpoint: '"https://blobstore.((DOMAIN))"'
    properties.cc.bulk_api_password: '"((BULK_API_PASSWORD))"'
    properties.cc.database_encryption.current_key_label: '"((CC_DB_CURRENT_KEY_LABEL))"'
    properties.cc.database_encryption.keys: ((CC_DB_ENCRYPTION_KEYS))
    properties.cc.db_encryption_key: '"((DB_ENCRYPTION_KEY))"'
    properties.cc.default_app_disk_in_mb: '"((DEFAULT_APP_DISK_IN_MB))"'
    properties.cc.default_app_memory: '"((DEFAULT_APP_MEMORY))"'
    properties.cc.default_app_ssh_access: '"((DEFAULT_APP_SSH_ACCESS))"'
    properties.cc.default_stack: '"((DEFAULT_STACK))"'
    properties.cc.diego.bbs.url: https://diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8889
    properties.cc.diego.cc_uploader_https_url: https://cc-uploader-cc-uploader.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):9091
    properties.cc.diego.docker_staging_stack: '"((DEFAULT_STACK))"'
    properties.cc.diego.file_server_url: http://diego-access.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8080
    properties.cc.diego.insecure_docker_registry_list: '[((INSECURE_DOCKER_REGISTRIES))]'
    properties.cc.diego.use_privileged_containers_for_running: ((USE_DIEGO_PRIVILEGED_CONTAINERS))
    properties.cc.diego.use_privileged_containers_for_staging: ((USE_STAGER_PRIVILEGED_CONTAINERS))
    properties.cc.disable_custom_buildpacks: ((DISABLE_CUSTOM_BUILDPACKS))
    properties.cc.droplets.max_staged_droplets_stored: ((DROPLET_MAX_STAGED_STORED))
    properties.cc.droplets.webdav_config.password: '"((BLOBSTORE_PASSWORD))"'
    properties.cc.droplets.webdav_config.private_endpoint: https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443
    properties.cc.droplets.webdav_config.public_endpoint: '"https://blobstore.((DOMAIN))"'
    properties.cc.internal_api_password: '"((INTERNAL_API_PASSWORD))"'
    properties.cc.internal_service_hostname: api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
    properties.cc.logging_level: '"((LOG_LEVEL))"'
    properties.cc.loggregator.internal_url: http://log-api-loggregator-trafficcontroller.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8081
    properties.cc.maximum_app_disk_in_mb: ((MAX_APP_DISK_IN_MB))
    properties.cc.maximum_health_check_timeout: ((MAX_HEALTH_CHECK_TIMEOUT))
    properties.cc.mutual_tls.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.cc.mutual_tls.private_key: '"((CC_SERVER_CRT_KEY))"'
    properties.cc.mutual_tls.public_cert: '"((CC_SERVER_CRT))"'
    properties.cc.nginx_error_log_level: '"((NGINX_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.cc.opi.enabled: ((FEATURE_EIRINI_ENABLED))
    properties.cc.opi.opi_staging: ((FEATURE_EIRINI_ENABLED))
    properties.cc.opi.url: http://eirini-opi.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8085
    properties.cc.packages.webdav_config.password: '"((BLOBSTORE_PASSWORD))"'
    properties.cc.packages.webdav_config.private_endpoint: https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443
    properties.cc.packages.webdav_config.public_endpoint: '"https://blobstore.((DOMAIN))"'
    properties.cc.public_tls.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.cc.public_tls.certificate: '"((CC_PUBLIC_TLS_CERT))"'
    properties.cc.public_tls.private_key: '"((CC_PUBLIC_TLS_CERT_KEY))"'
    properties.cc.resource_pool.webdav_config.password: '"((BLOBSTORE_PASSWORD))"'
    properties.cc.resource_pool.webdav_config.private_endpoint: https://blobstore-blobstore.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):4443
    properties.cc.resource_pool.webdav_config.public_endpoint: '"https://blobstore.((DOMAIN))"'
    properties.cc.security_event_logging.enabled: '"((ENABLE_SECURITY_EVENT_LOGGING))"'
    properties.cc.staging_timeout_in_seconds: ((STAGING_TIMEOUT))
    properties.cc.staging_upload_password: '"((STAGING_UPLOAD_PASSWORD))"'
    properties.cc.uaa.internal_url: ((KUBERNETES_NAMESPACE)).((UAA_HOST))
    properties.ccdb.address: mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
    properties.ccdb.roles: '[{"name": "ccadmin", "password": "((CC_DATABASE_PASSWORD))", "tag": "admin"}]'
    properties.cf-sle12.trusted_certs: '"((ROOTFS_TRUSTED_CERTS))((#ROOTFS_TRUSTED_CERTS))\n((/ROOTFS_TRUSTED_CERTS))((INTERNAL_CA_CERT))"'
    properties.cf-usb.broker.external_url: '"https://cf-usb.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):24054"'
    properties.cf-usb.broker.password: '"((CF_USB_PASSWORD))"'
    properties.cf-usb.broker.server_cert: '"((CF_USB_BROKER_SERVER_CERT))"'
    properties.cf-usb.broker.server_key: '"((CF_USB_BROKER_SERVER_CERT_KEY))"'
    properties.cf-usb.management.uaa.secret: '"((UAA_CLIENTS_CF_USB_SECRET))"'
    properties.cf-usb.mysql_address: 'mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))'
    properties.cf-usb.mysql_password: "((CF_USB_DATABASE_PASSWORD))"
    properties.cf.insecure_api_url: http://api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):9022 # For post-deployment-setup, because cf cli has no client certs.
    properties.cflinuxfs2-rootfs.trusted_certs: '"((ROOTFS_TRUSTED_CERTS))((#ROOTFS_TRUSTED_CERTS))\n((/ROOTFS_TRUSTED_CERTS))((INTERNAL_CA_CERT))"'
    properties.cflinuxfs3-rootfs.trusted_certs: '"((ROOTFS_TRUSTED_CERTS))((#ROOTFS_TRUSTED_CERTS))\n((/ROOTFS_TRUSTED_CERTS))((INTERNAL_CA_CERT))"'
    properties.containers.trusted_ca_certificates: '((#TRUSTED_CERTS))[((TRUSTED_CERTS))]((/TRUSTED_CERTS))'
    properties.copilot.client_ca_file: ((INTERNAL_CA_CERT))
    # CLUSTER_DESCRIPTION is not wrapped in quotes because it has quotes in the dev env file.
    properties.description: ((CLUSTER_DESCRIPTION))
    properties.diego.auctioneer.bbs.api_location: diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8889
    properties.diego.auctioneer.bbs.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.auctioneer.bbs.client_cert: '"((BBS_CLIENT_CRT))"'
    properties.diego.auctioneer.bbs.client_key: '"((BBS_CLIENT_CRT_KEY))"'
    properties.diego.auctioneer.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.auctioneer.locket.api_location: '"locket-locket.((KUBERNETES_NAMESPACE)):8891"'
    properties.diego.auctioneer.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.diego.auctioneer.rep.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.auctioneer.rep.client_cert: '"((AUCTIONEER_REP_CERT))"'
    properties.diego.auctioneer.rep.client_key: '"((AUCTIONEER_REP_CERT_KEY))"'
    properties.diego.auctioneer.server_cert: '"((AUCTIONEER_SERVER_CERT))"'
    properties.diego.auctioneer.server_key: '"((AUCTIONEER_SERVER_CERT_KEY))"'
    properties.diego.bbs.auctioneer.api_location: diego-brain-auctioneer.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):9016
    properties.diego.bbs.auctioneer.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.bbs.auctioneer.client_cert: '"((BBS_AUCTIONEER_CERT))"'
    properties.diego.bbs.auctioneer.client_key: '"((BBS_AUCTIONEER_CERT_KEY))"'
    properties.diego.bbs.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.bbs.encryption_keys: '[{"label": "active", "passphrase": "((BBS_ACTIVE_KEY_PASSPHRASE))"}]'
    properties.diego.bbs.locket.api_location: '"locket-locket.((KUBERNETES_NAMESPACE)):8891"'
    properties.diego.bbs.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.diego.bbs.rep.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.bbs.rep.client_cert: '"((BBS_REP_CERT))"'
    properties.diego.bbs.rep.client_key: '"((BBS_REP_CERT_KEY))"'
    properties.diego.bbs.server_cert: '"((BBS_SERVER_CRT))"'
    properties.diego.bbs.server_key: '"((BBS_SERVER_CRT_KEY))"'
    properties.diego.bbs.sql.ca_cert: ((INTERNAL_CA_CERT))
    properties.diego.bbs.sql.db_host: mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
    properties.diego.bbs.sql.db_password: ((DIEGO_DATABASE_PASSWORD))
    properties.diego.executor.disk_capacity_mb: ((DIEGO_CELL_DISK_CAPACITY_MB))
    properties.diego.executor.memory_capacity_mb: ((DIEGO_CELL_MEMORY_CAPACITY_MB))
    properties.diego.file_server.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.diego.locket.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.diego.locket.sql.db_host: '"mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.diego.locket.sql.db_password: '"((LOCKET_DATABASE_PASSWORD))"'
    properties.diego.rep.bbs.api_location: diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8889
    properties.diego.rep.cell_id: ((HOSTNAME))
    properties.diego.rep.locket.api_location: locket-locket.((KUBERNETES_NAMESPACE)):8891
    properties.diego.rep.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.diego.rep.placement_tags: "[((KUBE_PZ))]"
    properties.diego.rep.zone: '"((KUBE_AZ))"'
    properties.diego.route_emitter.bbs.api_location: diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8889
    properties.diego.route_emitter.bbs.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.route_emitter.bbs.client_cert: '"((BBS_CLIENT_CRT))"'
    properties.diego.route_emitter.bbs.client_key: '"((BBS_CLIENT_CRT_KEY))"'
    properties.diego.route_emitter.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.diego.route_emitter.nats.machines: ((KUBE_NATS_CLUSTER_IPS))((#KUBE_SIZING_NATS_COUNT))((/KUBE_SIZING_NATS_COUNT))
    properties.diego.route_emitter.nats.password: '"((NATS_PASSWORD))"'
    properties.diego.ssh_proxy.bbs.api_location: diego-api-bbs.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8889
    properties.diego.ssh_proxy.bbs.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.diego.ssh_proxy.bbs.client_cert: '"((BBS_CLIENT_CRT))"'
    properties.diego.ssh_proxy.bbs.client_key: '"((BBS_CLIENT_CRT_KEY))"'
    properties.diego.ssh_proxy.cc.internal_service_hostname: api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
    properties.diego.ssh_proxy.host_key: '"((APP_SSH_KEY))"'
    properties.diego.ssh_proxy.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.diego.ssh_proxy.uaa.ca_cert: ((UAA_CA_CERT))
    properties.diego.ssh_proxy.uaa.port: ((UAA_PORT))
    properties.diego.ssh_proxy.uaa.url: https://((KUBERNETES_NAMESPACE)).((UAA_HOST))
    properties.diego.ssh_proxy.uaa_secret: '"((UAA_CLIENTS_DIEGO_SSH_PROXY_SECRET))"'
    properties.domain: '"((DOMAIN))"'
    properties.eirini-extensions.kube_service_host: "((KUBERNETES_SERVICE_HOST))"
    properties.eirini-extensions.kube_service_port: "((KUBERNETES_SERVICE_PORT))"
    properties.eirini-extensions.namespace: "((EIRINI_KUBE_NAMESPACE))"
    properties.eirini-extensions.operator_webhook_host: "((EIRINI_EIRINI_EXTENSIONS_SERVICE_HOST))"
    properties.eirini-persi-broker.auth_password: '"((EIRINI_PERSI_NFS_BROKER_PASSWORD))"'
    properties.eirini-persi-broker.kube_service_host: "((KUBERNETES_SERVICE_HOST))"
    properties.eirini-persi-broker.kube_service_port: "((KUBERNETES_SERVICE_PORT))"
    properties.eirini-persi-broker.namespace: "((EIRINI_KUBE_NAMESPACE))"
    properties.eirini-persi-broker.service_plans: '((EIRINI_PERSI_PLANS))'
    properties.eirini-persi-broker.url: 'http://eirini-eirini-persi-broker.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8999'
    properties.external_cert: '"((LOG_CACHE_CF_AUTH_PROXY_EXTERNAL_CERT))"'
    properties.external_key: '"((LOG_CACHE_CF_AUTH_PROXY_EXTERNAL_CERT_KEY))"'
    properties.fissile.monit.password: '"((MONIT_PASSWORD))"'
    properties.garden.apparmor_profile: '"((GARDEN_APPARMOR_PROFILE))"' # Quoting needed to pass through empty string
    properties.garden.btrfs-active: "((^GARDEN_DISABLE_BTRFS))true((/GARDEN_DISABLE_BTRFS))"
    properties.garden.dns_servers: '[((GARDEN_LINUX_DNS_SERVER))]'
    properties.garden.docker_registry_endpoint: ((GARDEN_DOCKER_REGISTRY))((^GARDEN_DOCKER_REGISTRY))null((/GARDEN_DOCKER_REGISTRY))
    properties.garden.http_proxy: '"((HTTP_PROXY))"'
    properties.garden.https_proxy: '"((HTTPS_PROXY))"'
    properties.garden.image_plugin: "((^GARDEN_DISABLE_BTRFS))/var/vcap/packages/groot-btrfs/bin/groot-btrfs((/GARDEN_DISABLE_BTRFS))"
    properties.garden.image_plugin_extra_args: ((^GARDEN_DISABLE_BTRFS))["--config", "/var/vcap/jobs/groot-btrfs/config/groot-btrfs.yaml"]((/GARDEN_DISABLE_BTRFS))
    properties.garden.insecure_docker_registry_list: '[((INSECURE_DOCKER_REGISTRIES))]'
    properties.garden.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.garden.network_mtu: ((DIEGO_CELL_NETWORK_MTU))
    properties.garden.network_pool: '"((DIEGO_CELL_SUBNET))"'
    properties.garden.no_proxy: '"((NO_PROXY))"'
    properties.garden.privileged_image_plugin: "((^GARDEN_DISABLE_BTRFS))/var/vcap/packages/groot-btrfs/bin/groot-btrfs((/GARDEN_DISABLE_BTRFS))"
    properties.garden.privileged_image_plugin_extra_args: ((^GARDEN_DISABLE_BTRFS))["--config", "/var/vcap/jobs/groot-btrfs/config/groot-btrfs-privileged.yaml"]((/GARDEN_DISABLE_BTRFS))
    properties.grootfs.insecure_docker_registry_list: '[((INSECURE_DOCKER_REGISTRIES))]'
    # How to reach the capi.cc_uploader
    properties.internal_hostname: cc-uploader-cc-uploader.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))
    properties.locks.locket.hostname: locket-locket.((KUBERNETES_NAMESPACE))
    properties.loggregator.ca_cert: ((INTERNAL_CA_CERT))
    properties.loggregator.cert: ((LOGGREGATOR_CLIENT_CERT))
    properties.loggregator.key: ((LOGGREGATOR_CLIENT_CERT_KEY))
    properties.loggregator.tls.agent.cert: '"((LOGGREGATOR_AGENT_CERT))"'
    properties.loggregator.tls.agent.key: '"((LOGGREGATOR_AGENT_CERT_KEY))"'
    properties.loggregator.tls.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.loggregator.tls.cc_trafficcontroller.cert: ((TRAFFICCONTROLLER_CERT))
    properties.loggregator.tls.cc_trafficcontroller.key: ((TRAFFICCONTROLLER_CERT_KEY))
    properties.loggregator.tls.doppler.cert: '"((DOPPLER_CERT))"'
    properties.loggregator.tls.doppler.key: '"((DOPPLER_CERT_KEY))"'
    properties.loggregator.tls.reverse_log_proxy.cert: '"((SYSLOG_RLP_CERT))"'
    properties.loggregator.tls.reverse_log_proxy.key: '"((SYSLOG_RLP_CERT_KEY))"'
    properties.loggregator.tls.statsd_injector.cert: '"((CC_SERVER_CRT))"'
    properties.loggregator.tls.statsd_injector.key: '"((CC_SERVER_CRT_KEY))"'
    properties.loggregator.tls.trafficcontroller.cert: '"((TRAFFICCONTROLLER_CERT))"'
    properties.loggregator.tls.trafficcontroller.key: '"((TRAFFICCONTROLLER_CERT_KEY))"'
    properties.loggregator.uaa.client_secret: '"((UAA_CLIENTS_DOPPLER_SECRET))"'
    properties.loggregator_agent.tls.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.loggregator_agent.tls.cert: '"((LOG_CACHE_TO_LOGGREGATOR_AGENT_CERT))"'
    properties.loggregator_agent.tls.key: '"((LOG_CACHE_TO_LOGGREGATOR_AGENT_CERT_KEY))"'
    properties.login.url: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))
    # CLUSTER_NAME is not wrapped in quotes because it has quotes in the dev env file.
    properties.name: ((CLUSTER_NAME))
    properties.nats.machines: ((KUBE_NATS_CLUSTER_IPS))((#KUBE_SIZING_NATS_COUNT))((/KUBE_SIZING_NATS_COUNT))
    properties.nats.password: '"((NATS_PASSWORD))"'
    properties.nfsbroker.allowed_options: '"((PERSI_NFS_ALLOWED_OPTIONS))"'
    properties.nfsbroker.db_hostname: 'mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))'
    properties.nfsbroker.db_password: '"((PERSI_NFS_DATABASE_PASSWORD))"'
    properties.nfsbroker.default_options: '"((PERSI_NFS_DEFAULT_OPTIONS))"'
    properties.nfsbroker.password: '"((PERSI_NFS_BROKER_PASSWORD))"'
    properties.nfsbroker.url: 'http://nfs-broker-nfsbroker.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8999'
    properties.nfsv3driver.allowed-in-mount: '"((PERSI_NFS_DRIVER_ALLOWED_IN_MOUNT))"'
    properties.nfsv3driver.allowed-in-source: '"((PERSI_NFS_DRIVER_ALLOWED_IN_SOURCE))"'
    properties.nfsv3driver.default-in-mount: '"((PERSI_NFS_DRIVER_DEFAULT_IN_MOUNT))"'
    properties.nfsv3driver.default-in-source: '"((PERSI_NFS_DRIVER_DEFAULT_IN_SOURCE))"'
    properties.nfsv3driver.disable: '((PERSI_NFS_DRIVER_DISABLE))'
    properties.nfsv3driver.ldap_host: '"((PERSI_NFS_DRIVER_LDAP_HOST))"'
    properties.nfsv3driver.ldap_port: '"((PERSI_NFS_DRIVER_LDAP_PORT))"'
    properties.nfsv3driver.ldap_proto: '"((PERSI_NFS_DRIVER_LDAP_PROTOCOL))"'
    properties.nfsv3driver.ldap_svc_password: '"((PERSI_NFS_DRIVER_LDAP_PASSWORD))"'
    properties.nfsv3driver.ldap_svc_user: '"((PERSI_NFS_DRIVER_LDAP_USER))"'
    properties.nfsv3driver.ldap_user_fqdn: '"((PERSI_NFS_DRIVER_LDAP_USER_FQDN))"'
    properties.nfsv3driver.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'

    properties.opi.cc_ca: "((INTERNAL_CA_CERT))"
    properties.opi.cc_cert: "((CC_SERVER_CRT))"
    properties.opi.cc_internal_api: "https://api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):9023"
    properties.opi.cc_key: "((CC_SERVER_CRT_KEY))"
    properties.opi.cc_uploader_ip: "((CC_UPLOADER_CC_UPLOADER_SERVICE_HOST))"
    properties.opi.eirini_address: "http://eirini-opi.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8085"
    properties.opi.kube_namespace: "((EIRINI_KUBE_NAMESPACE))"
    properties.opi.kube_service_host: "((KUBERNETES_SERVICE_HOST))"
    properties.opi.kube_service_port: "((KUBERNETES_SERVICE_PORT))"
    properties.opi.loggregator_address: "doppler-doppler.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8082"
    properties.opi.loggregator_ca: "((INTERNAL_CA_CERT))"
    properties.opi.loggregator_cert: "((DOPPLER_CERT))"
    properties.opi.loggregator_key: "((DOPPLER_CERT_KEY))"
    properties.opi.metrics_source_address: "((EIRINI_KUBE_HEAPSTER_ADDRESS))"
    # TODO: this needs to be fixed upstream - it should be an array
    properties.opi.nats_ip: "nats-0.nats-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"
    properties.opi.nats_password: "((NATS_PASSWORD))"
    properties.opi.registry_address: "registry.((DOMAIN))"
    properties.opi.stager_image: ((EIRINI_IMAGE))

    properties.router.balancing_algorithm: '"((ROUTER_BALANCING_ALGORITHM))"'
    properties.router.client_cert_validation: '"((ROUTER_CLIENT_CERT_VALIDATION))"'
    # We use mysql because it comes up without any other dependencies and its critical for the cluster
    properties.router.dns_health_check_host: 'mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)).'
    properties.router.force_forwarded_proto_https: ((FORCE_FORWARDED_PROTO_AS_HTTPS))
    properties.router.forwarded_client_cert: "((ROUTER_FORWARDED_CLIENT_CERT))"
    properties.router.logging_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.router.route_services_secret: '"((ROUTER_SERVICES_SECRET))"'
    properties.router.status.password: '"((ROUTER_STATUS_PASSWORD))"'
    properties.router.tls_pem: '((#ROUTER_TLS_PEM))((ROUTER_TLS_PEM))((/ROUTER_TLS_PEM))((^ROUTER_TLS_PEM))[{cert_chain: "((ROUTER_SSL_CERT))", private_key: "((ROUTER_SSL_CERT_KEY))"}]((/ROUTER_TLS_PEM))'
    properties.routing_api.locket.api_location: '"locket-locket.((KUBERNETES_NAMESPACE)):8891"'
    properties.routing_api.locket.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.routing_api.locket.client_cert: '"((DIEGO_CLIENT_CERT))"'
    properties.routing_api.locket.client_key: '"((DIEGO_CLIENT_CERT_KEY))"'
    properties.routing_api.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.routing_api.port: 3000((#KUBERNETES_NAMESPACE))((/KUBERNETES_NAMESPACE))
    properties.routing_api.router_groups: '[{"name":"default-tcp", "type":"tcp", "reservable_ports":"((KUBE_SIZING_TCP_ROUTER_PORTS_TCP_ROUTE_MIN))-((KUBE_SIZING_TCP_ROUTER_PORTS_TCP_ROUTE_MAX))"}]'
    properties.routing_api.sqldb.host: "mysql-proxy-set.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"
    properties.routing_api.sqldb.password: "((ROUTING_API_DATABASE_PASSWORD))"
    properties.routing_api.system_domain: '"((DOMAIN))"'
    properties.routing_api.uri: '"http://routing-api-routing-api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.routing_api.url: '"http://routing-api-routing-api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"'
    properties.scalablesyslog.adapter.logs.addr: '"log-api-reverse-log-proxy.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8082"'
    properties.scalablesyslog.adapter.tls.ca: '"((INTERNAL_CA_CERT))"'
    properties.scalablesyslog.adapter.tls.cert: '"((SYSLOG_ADAPT_CERT))"'
    properties.scalablesyslog.adapter.tls.key: '"((SYSLOG_ADAPT_CERT_KEY))"'
    properties.scalablesyslog.adapter_rlp.tls.ca: '"((INTERNAL_CA_CERT))"'
    properties.scalablesyslog.adapter_rlp.tls.cert: '"((SYSLOG_ADAPT_CERT))"'
    properties.scalablesyslog.adapter_rlp.tls.key: '"((SYSLOG_ADAPT_CERT_KEY))"'
    properties.scalablesyslog.scheduler.api.url: https://api.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):9023
    properties.scalablesyslog.scheduler.tls.api.ca: '"((INTERNAL_CA_CERT))"'
    properties.scalablesyslog.scheduler.tls.api.cert: '"((SYSLOG_SCHED_CERT))"'
    properties.scalablesyslog.scheduler.tls.api.key: '"((SYSLOG_SCHED_CERT_KEY))"'
    properties.scalablesyslog.scheduler.tls.client.ca: '"((INTERNAL_CA_CERT))"'
    properties.scalablesyslog.scheduler.tls.client.cert: '"((SYSLOG_SCHED_CERT))"'
    properties.scalablesyslog.scheduler.tls.client.key: '"((SYSLOG_SCHED_CERT_KEY))"'

    properties.scf.eirini.cert_copier_image: "((EIRINI_CERT_COPIER_IMAGE))"
    properties.scf.eirini.doppler_address: "doppler-doppler.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8082"
    properties.scf.eirini.doppler_address_with_az: "doppler-doppler.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN)):8082"
    properties.scf.eirini.enabled: ((FEATURE_EIRINI_ENABLED))
    properties.scf.eirini.fluentd_image: "((EIRINI_FLUENTD_IMAGE))"
    properties.scf.eirini.namespace: "((EIRINI_KUBE_NAMESPACE))"
    properties.scf.eirini.registry.address: "registry.((DOMAIN))"

    properties.scf.internal-ca-cert: '"((INTERNAL_CA_CERT))"'
    properties.scf.secrets_generation_name: "((KUBE_SECRETS_GENERATION_NAME))"
    properties.scf.uaa.internal-url: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))
    properties.scf.uaa.root-zone.url: https://((UAA_HOST)):((UAA_PORT))
    properties.scf_set_proxy.running_http_proxy: '"((HTTP_PROXY))"'
    properties.scf_set_proxy.running_https_proxy: '"((HTTPS_PROXY))"'
    properties.scf_set_proxy.running_no_proxy: '"((NO_PROXY))"'
    properties.scf_set_proxy.staging_http_proxy: '"((HTTP_PROXY))"'
    properties.scf_set_proxy.staging_https_proxy: '"((HTTPS_PROXY))"'
    properties.scf_set_proxy.staging_no_proxy: '"((NO_PROXY))"'
    properties.sle15-rootfs.trusted_certs: '"((ROOTFS_TRUSTED_CERTS))((#ROOTFS_TRUSTED_CERTS))\n((/ROOTFS_TRUSTED_CERTS))((INTERNAL_CA_CERT))"'
    properties.smoke_tests.api: '"api.((DOMAIN))"'
    properties.smoke_tests.apps_domain: '["((DOMAIN))"]'
    properties.smoke_tests.autoscaler_endpoint: '"https://autoscaler.((DOMAIN))"'
    properties.smoke_tests.password: '"((CLUSTER_ADMIN_PASSWORD))"'
    properties.support_address: '"((SUPPORT_ADDRESS))"'
    properties.system_domain: '"((DOMAIN))"'
    properties.tcp_router.log_level: '"((GO_LOG_LEVEL))((#LOG_LEVEL))((/LOG_LEVEL))"'
    properties.tcp_router.oauth_secret: '"((UAA_CLIENTS_TCP_ROUTER_SECRET))"'
    properties.tls.ca_cert: '"((INTERNAL_CA_CERT))"'
    properties.tls.cert: '"((DIEGO_CLIENT_CERT))"'
    properties.tls.key: '"((DIEGO_CLIENT_CERT_KEY))"'
    properties.uaa.admin.client_secret: '"((UAA_ADMIN_CLIENT_SECRET))"'
    properties.uaa.ca_cert: '"((UAA_CA_CERT))((^UAA_CA_CERT))((INTERNAL_CA_CERT))((/UAA_CA_CERT))"'
    properties.uaa.client_secret: '"((UAA_CLIENTS_TCP_EMITTER_SECRET))"'
    properties.uaa.clients.app_autoscaler.secret: ((AUTOSCALER_UAA_CLIENT_SECRET))
    properties.uaa.clients.cc-service-dashboards.secret: '"((UAA_CLIENTS_CC_SERVICE_DASHBOARDS_CLIENT_SECRET))"'
    properties.uaa.clients.cc_routing.secret: '"((UAA_CLIENTS_CC_ROUTING_SECRET))"'
    properties.uaa.clients.cc_service_key_client.secret: '"((UAA_CLIENTS_CC_SERVICE_KEY_CLIENT_SECRET))"'
    properties.uaa.clients.cf-usb.secret: '"((UAA_CLIENTS_CF_USB_SECRET))"'
    properties.uaa.clients.cf.redirect-uri: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))/login
    properties.uaa.clients.cf_smoke_tests.secret: ((UAA_CLIENTS_CF_SMOKE_TESTS_CLIENT_SECRET))
    properties.uaa.clients.cloud_controller_username_lookup.secret: '"((UAA_CLIENTS_CLOUD_CONTROLLER_USERNAME_LOOKUP_SECRET))"'
    properties.uaa.clients.credhub_user_cli.secret: '"((UAA_CLIENTS_CREDHUB_USER_CLI_SECRET))"'
    properties.uaa.clients.doppler.redirect-uri: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))
    properties.uaa.clients.doppler.secret: '"((UAA_CLIENTS_DOPPLER_SECRET))"'
    properties.uaa.clients.gorouter.secret: '"((UAA_CLIENTS_GOROUTER_SECRET))"'
    properties.uaa.clients.routing_api_client.secret: ((UAA_CLIENTS_ROUTING_API_CLIENT_SECRET))
    properties.uaa.clients.scf_auto_config.secret: '"((UAA_CLIENTS_SCF_AUTO_CONFIG_SECRET))"'
    properties.uaa.clients.ssh-proxy.redirect-uri: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))/login
    properties.uaa.clients.ssh-proxy.secret: '"((UAA_CLIENTS_DIEGO_SSH_PROXY_SECRET))"'
    properties.uaa.clients.tcp_emitter.secret: '"((UAA_CLIENTS_TCP_EMITTER_SECRET))"'
    properties.uaa.clients.tcp_router.secret: '"((UAA_CLIENTS_TCP_ROUTER_SECRET))"'
    properties.uaa.hostname: '((KUBERNETES_NAMESPACE)).((UAA_HOST))'
    properties.uaa.internal_url: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT)) # For loggregator
    properties.uaa.port: ((UAA_PORT))
    properties.uaa.scim.users: '[{name: admin, password: ((CLUSTER_ADMIN_PASSWORD)), groups: [((CLUSTER_ADMIN_AUTHORITIES))]}]'
    properties.uaa.ssl.port: ((UAA_PORT))
    properties.uaa.tls_port: ((UAA_PORT))
    properties.uaa.token_endpoint: ((KUBERNETES_NAMESPACE)).((UAA_HOST))
    properties.uaa.url: https://((KUBERNETES_NAMESPACE)).((UAA_HOST)):((UAA_PORT))
    properties.version: '"((CLUSTER_VERSION))"'
    # Really a loggregator_agent job property
    properties.zone: '"((KUBE_AZ))"'
variables:
- name: ACCEPTANCE_TEST_NODES
  options:
    default: 4
    description: >
      The number of parallel test executors to spawn for Cloud Foundry
      acceptance tests. The larger the number the higher the stress on the system.
- name: ALLOWED_CORS_DOMAINS
  options:
    default: []
    description: List of domains (including scheme) from which Cross-Origin requests
      will be accepted, a * can be used as a wildcard for any part of a domain.
    required: true
- name: ALLOW_APP_SSH_ACCESS
  options:
    default: true
    description: Allow users to change the value of the app-level allow_ssh attribute.
    required: true
- name: APP_SSH_KEY
  options:
    secret: true
    description: PEM encoded RSA private key used to identify host.
    required: true
  type: ssh
- name: APP_SSH_KEY_FINGERPRINT
  options:
    secret: true
    description: MD5 fingerprint of the host key of the SSH proxy that brokers connections
      to application instances.
    required: true
- name: APP_TOKEN_UPLOAD_GRACE_PERIOD
  options:
    default: 1200
    description: Extra token expiry time while uploading big apps, in seconds.
    required: true
- name: AUCTIONEER_REP_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded certificate
    required: true
  type: certificate
- name: AUCTIONEER_REP_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key
    required: true
- name: AUCTIONEER_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: diego-brain-auctioneer
    description: PEM-encoded server certificate
    required: true
  type: certificate
- name: AUCTIONEER_SERVER_CERT_KEY
  options:
    secret: true
    description: PEM-encoded server key
    required: true
- name: AUTOSCALER_ASAPI_PUBLIC_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - autoscaler.{{.DOMAIN}}
    - localhost
    description: A PEM-encoded TLS certificate of the Autoscaler API public https
      server. This includes the Autoscaler ApiServer and the Service Broker.
    required: true
  type: certificate
- name: AUTOSCALER_ASAPI_PUBLIC_SERVER_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key of the Autoscaler API public https server.
      This includes the Autoscaler ApiServer and the Service Broker.
    required: true
- name: AUTOSCALER_ASAPI_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - autoscaler-api-apiserver.{{.KUBERNETES_NAMESPACE}}.svc.{{.KUBERNETES_CLUSTER_DOMAIN}}
    - localhost
    description: A PEM-encoded TLS certificate of the Autoscaler API https server.
      This includes the Autoscaler ApiServer and the Service Broker.
    required: true
  type: certificate
- name: AUTOSCALER_ASAPI_SERVER_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key of the Autoscaler API https server. This includes
      the Autoscaler ApiServer and the Service Broker.
    required: true
- name: AUTOSCALER_ASMETRICS_CLIENT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: A PEM-encoded TLS certificate for clients to connect to the Autoscaler
      Metrics. This includes the Autoscaler Metrics Collector and Event Generator.
    required: true
  type: certificate
- name: AUTOSCALER_ASMETRICS_CLIENT_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key for clients to connect to the Autoscaler Metrics.
      This includes the Autoscaler Metrics Collector and Event Generator.
    required: true
- name: AUTOSCALER_ASMETRICS_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - autoscaler-metrics-metricscollector.{{.KUBERNETES_NAMESPACE}}.svc.{{.KUBERNETES_CLUSTER_DOMAIN}}
    - autoscaler-metrics-eventgenerator.{{.KUBERNETES_NAMESPACE}}.svc.{{.KUBERNETES_CLUSTER_DOMAIN}}
    - localhost
    description: A PEM-encoded TLS certificate of the Autoscaler Metrics https server.
      This includes the Autoscaler Metrics Collector.
    required: true
  type: certificate
- name: AUTOSCALER_ASMETRICS_SERVER_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key of the Autoscaler Metrics https server. This
      includes the Autoscaler Metrics Collector.
    required: true
- name: AUTOSCALER_DB_ADDRESS
  options:
    default: "autoscaler-postgres-postgres.((KUBERNETES_NAMESPACE)).svc.((KUBERNETES_CLUSTER_DOMAIN))"
    description: The db address for the Autoscaler postgres database.
- name: AUTOSCALER_DB_PASSWORD
  options:
    secret: true
    description: The password for the Autoscaler postgres database.
    required: true
  type: password
- name: AUTOSCALER_DB_PORT
  options:
    default: 5432
    description: "The tcp port of postgres database serves on"  
- name: AUTOSCALER_DB_ROLE_NAME
  options:
    default: "postgres"
    description: "The role name of autoscaler postgres database"       
- name: AUTOSCALER_SCALING_ENGINE_CLIENT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: A PEM-encoded TLS certificate for clients to connect to the Autoscaler Scaling Engine.
    required: true
  type: certificate
- name: AUTOSCALER_SCALING_ENGINE_CLIENT_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key for clients to connect to the Autoscaler Scaling Engine.
    required: true
- name: AUTOSCALER_SCALING_ENGINE_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - autoscaler-actors-scalingengine.{{.KUBERNETES_NAMESPACE}}.svc.{{.KUBERNETES_CLUSTER_DOMAIN}}
    - localhost
    description: A PEM-encoded TLS certificate of the Autoscaler Scaling Engine https server.
    required: true
  type: certificate
- name: AUTOSCALER_SCALING_ENGINE_SERVER_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key of the Autoscaler Scaling Engine https server.
    required: true
- name: AUTOSCALER_SCHEDULER_CLIENT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: A PEM-encoded TLS certificate for clients to connect to the Autoscaler Scheduler.
    required: true
  type: certificate
- name: AUTOSCALER_SCHEDULER_CLIENT_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key for clients to connect to the Autoscaler Scheduler.
    required: true
- name: AUTOSCALER_SCHEDULER_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - autoscaler-actors-scheduler.{{.KUBERNETES_NAMESPACE}}.svc.{{.KUBERNETES_CLUSTER_DOMAIN}}
    - localhost
    description: A PEM-encoded TLS certificate of the Autoscaler Scheduler https server.
    required: true
  type: certificate
- name: AUTOSCALER_SCHEDULER_SERVER_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key of the Autoscaler Scheduler https server.
    required: true
- name: AUTOSCALER_UAA_CLIENT_SECRET
  options:
    secret: true
    description: the uaa client secret used by Autoscaler.
  type: password
- name: AZ_LABEL_NAME
  options:
    default: ''
    description: The name of the metadata label to query on worker
      nodes to get AZ information. When set, the cells will query
      their worker node for AZ information and inject the result into
      cloudfoundry via the KUBE_AZ parameter. When left to the default
      no custom AZ processing is done.
    internal: true
- name: BBS_ACTIVE_KEY_PASSPHRASE
  options:
    secret: true
    immutable: true
    description: The password for access to the diego BBS database.
    required: true
  type: password
- name: BBS_AUCTIONEER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded certificate
    required: true
  type: certificate
- name: BBS_AUCTIONEER_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key
    required: true
- name: BBS_CLIENT_CRT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded client certificate.
    required: true
  type: certificate
- name: BBS_CLIENT_CRT_KEY
  options:
    secret: true
    description: PEM-encoded client key.
    required: true
- name: BBS_REP_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded certificate
    required: true
  type: certificate
- name: BBS_REP_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key
    required: true
- name: BBS_SERVER_CRT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: diego-api-bbs
    description: PEM-encoded client certificate.
    required: true
  type: certificate
- name: BBS_SERVER_CRT_KEY
  options:
    secret: true
    description: PEM-encoded client key.
    required: true

- name: BITS_ADMIN_USERS_PASSWORD
  options:
    secret: true
    description: The basic auth password that the Cloud Controller uses to connect to the admin endpoint on webdav.
    required: true
  type: password
- name: BITS_SERVICE_SECRET
  options:
    secret: true
    description: This is the key secret Bits-Service uses and clients should use to generate signed URLs.
    required: true
  type: password
- name: BITS_SERVICE_SSL_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: bits
    description: PEM-encoded client certificate.
    required: true
    alternative_names:
    - bits-bits-service.{{.KUBERNETES_NAMESPACE}}.svc.{{.KUBERNETES_CLUSTER_DOMAIN}}
  type: certificate
- name: BITS_SERVICE_SSL_CERT_KEY
  options:
    secret: true
    description: PEM-encoded client key.
    required: true

- name: BLOBSTORE_ACCESS_RULES
  options:
    default: allow 10.0.0.0/8; allow 172.16.0.0/12; allow 192.168.0.0/16;
    description: List of allow / deny rules for the blobstore internal server. Will
      be followed by 'deny all'. Each entry must be follow by a semicolon.
    required: true
- name: BLOBSTORE_MAX_UPLOAD_SIZE
  options:
    default: 5000
    description: Maximal allowed file size for upload to blobstore, in megabytes.
    required: true
- name: BLOBSTORE_PASSWORD
  options:
    secret: true
    description: The basic auth password that Cloud Controller uses to connect to
      the blobstore server. Auto-generated if not provided. Passwords must be alphanumeric
      (URL-safe).
    required: true
  type: password
- name: BLOBSTORE_SECURE_LINK
  options:
    secret: true
    description: The secret used for signing URLs between Cloud Controller and blobstore.
    required: true
  type: password
- name: BLOBSTORE_TLS_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: blobstore-blobstore
    description: The PEM-encoded certificate (optionally as a certificate chain) for
      serving blobs over TLS/SSL.
    required: true
  type: certificate
- name: BLOBSTORE_TLS_CERT_KEY
  options:
    secret: true
    description: The PEM-encoded private key for signing TLS/SSL traffic.
    required: true
- name: BROKER_CLIENT_TIMEOUT_SECONDS
  options:
    default: '70'
    description: For requests to service brokers, this is the HTTP (open and read)
      timeout setting, in seconds.
- name: BULK_API_PASSWORD
  options:
    secret: true
    description: The password for the bulk api.
    required: true
  type: password
- name: CATS_SUITES
  options:
    internal: true
    description: The set of CAT test suites to run. If not specified it falls back
      to a hardwired set of suites.
- name: CC_DATABASE_PASSWORD
  options:
    previous_names:
    - CCDB_ROLE_PASSWORD
    - MYSQL_CCDB_ROLE_PASSWORD
    secret: true
    description: The password for access to the Cloud Controller database.
    required: true
  type: password
- name: CC_DB_CURRENT_KEY_LABEL
  options:
    description: The key used to encrypt entries in the CC database
    default: ''
- name: CC_DB_ENCRYPTION_KEYS
  options:
    description: A map of labels and encryption keys
    secret: true
    default: "~"
- name: CC_PUBLIC_TLS_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - "api"
    - "api-set"
    - "api-set.{{ .KUBERNETES_NAMESPACE }}.svc.{{ .KUBERNETES_CLUSTER_DOMAIN }}"
    - "api.{{ .KUBERNETES_NAMESPACE }}.svc.{{ .KUBERNETES_CLUSTER_DOMAIN }}"
    description: The PEM-encoded certificate for secure TLS communication over external endpoints.
    required: true
  type: certificate
- name: CC_PUBLIC_TLS_CERT_KEY
  options:
    secret: true
    description: The PEM-encoded key for secure TLS communication over external endpoints.
    required: true
- name: CC_SERVER_CRT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: api
    description: The PEM-encoded certificate for internal cloud controller traffic.
    required: true
  type: certificate
- name: CC_SERVER_CRT_KEY
  options:
    secret: true
    description: The PEM-encoded private key for internal cloud controller traffic.
    required: true
- name: CC_UPLOADER_CC_UPLOADER_SERVICE_HOST
  options:
    type: environment
    description: IP of the cc uploader service. This is automatically set by Kubernetes.
      traffic.
- name: CC_UPLOADER_CRT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: cc-uploader-cc-uploader
    description: The PEM-encoded certificate for internal cloud controller uploader
      traffic.
    required: true
  type: certificate
- name: CC_UPLOADER_CRT_KEY
  options:
    secret: true
    description: The PEM-encoded private key for internal cloud controller uploader
      traffic.
    required: true
- name: CDN_URI
  options:
    default: ''
    description: URI for a CDN to use for buildpack downloads.
- name: CERT_EXPIRATION
  options:
    description: Expiration for generated certificates (in days)
    default: 10950
- name: CF_MYSQL_PROXY_API_PASSWORD
  options:
    previous_names:
    - MYSQL_PROXY_ADMIN_PASSWORD
    secret: true
    description: The password for Basic Auth used to secure the MySQL proxy API.
    required: true
  type: password
- name: CF_USB_BROKER_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: cf-usb
    description: PEM-encoded broker server certificate.
  type: certificate
- name: CF_USB_BROKER_SERVER_CERT_KEY
  options:
    secret: true
    description: PEM-encoded broker server key.
- name: CF_USB_DATABASE_PASSWORD
  options:
    previous_names:
    - MYSQL_CF_USB_PASSWORD
    secret: true
    example: password
    description: The password for access to the usb config database.
  type: password
- name: CF_USB_PASSWORD
  options:
    secret: true
    example: password
    description: The password for access to the Universal Service Broker.
  type: password
- name: CLUSTER_ADMIN_AUTHORITIES
  options:
    default: scim.write,scim.read,openid,cloud_controller.admin,clients.read,clients.write,doppler.firehose,routing.router_groups.read,routing.router_groups.write
    description: The Oauth2 authorities available to the cluster administrator.
    required: true
- name: CLUSTER_ADMIN_PASSWORD
  options:
    secret: true
    description: The password for the cluster administrator.
    required: true
- name: CLUSTER_BUILD
  options:
    default: 2.16.4
    description: "'build' attribute in the /v2/info endpoint"
    required: true
- name: CLUSTER_DESCRIPTION
  options:
    default: SUSE Cloud Foundry
    description: "'description' attribute in the /v2/info endpoint"
    required: true
- name: CLUSTER_NAME
  options:
    default: SCF
    description: "'name' attribute in the /v2/info endpoint"
    required: true
- name: CLUSTER_VERSION
  options:
    default: 2
    description: "'version' attribute in the /v2/info endpoint"
    required: true
- name: CREDHUB_DATABASE_PASSWORD
  options:
    previous_names:
    - MYSQL_CREDHUB_USER_PASSWORD
    secret: true
    description: The password for access to the credhub-user database.
    required: true
  type: password
- name: CREDHUB_ENCRYPT_KEY
  options:
    secret: true
    immutable: true
    description: Credhub encryption key
    required: true
  type: password
- name: CREDHUB_LOG_LEVEL
  options:
    description: >
      The log level for credhub. This parameter is not supposed to be set
      by the user. To change the cluster's log level set the parameter
      `LOG_LEVEL` instead, from which this one is derived.
    type: environment
- name: CREDHUB_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - "credhub-set"
    - "server.dc1.{{.KUBERNETES_NAMESPACE}}.svc.{{.KUBERNETES_CLUSTER_DOMAIN}}"
    description: PEM-encoded server certificate
    required: true
  type: certificate
- name: CREDHUB_SERVER_CERT_KEY
  options:
    secret: true
    description: PEM-encoded server key
    required: true
- name: DB_ENCRYPTION_KEY
  options:
    secret: true
    immutable: true
    description: Key for encrypting sensitive values in the Cloud Controller database.
    required: true
  type: password
- name: DEFAULT_APP_DISK_IN_MB
  options:
    default: 1024
    description: The standard amount of disk (in MB) given to an application when
      not overriden by the user via manifest, command line, etc.
    required: true
- name: DEFAULT_APP_MEMORY
  options:
    default: 1024
    description: The standard amount of memory (in MB) given to an application when
      not overriden by the user via manifest, command line, etc.
    required: true
- name: DEFAULT_APP_SSH_ACCESS
  options:
    default: true
    description: If set apps pushed to spaces that allow SSH access will have SSH
      enabled by default.
    required: true
- name: DEFAULT_STACK
  options:
    default: sle15
    description: The default stack to use if no custom stack is specified by an app.
- name: DIEGO_CELL_DISK_CAPACITY_MB
  options:
    default: auto
    description: The container disk capacity the cell should manage. If this capacity
      is larger than the actual disk quota of the cell component, over-provisioning
      will occur.
    required: true
- name: DIEGO_CELL_MEMORY_CAPACITY_MB
  options:
    default: auto
    description: The memory capacity the cell should manage. If this capacity is larger
      than the actual memory of the cell component, over-provisioning will occur.
    required: true
- name: DIEGO_CELL_NETWORK_MTU
  options:
    default: '1400'
    description: Maximum network transmission unit length in bytes for application
      containers.
    required: true
- name: DIEGO_CELL_SUBNET
  options:
    default: 10.38.0.0/16
    description: A CIDR subnet mask specifying the range of subnets available to be
      assigned to containers.
    required: true
- name: DIEGO_CLIENT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - locket-locket.{{.KUBERNETES_NAMESPACE}}
    - 127.0.0.1
    description: PEM-encoded client certificate
    required: true
  type: certificate
- name: DIEGO_CLIENT_CERT_KEY
  options:
    secret: true
    description: PEM-encoded client key
    required: true
- name: DIEGO_DATABASE_PASSWORD
  options:
    previous_names:
    - MYSQL_DIEGO_PASSWORD
    secret: true
    description: The password for access to MySQL by diego.
    required: true
  type: password
- name: DISABLE_CUSTOM_BUILDPACKS
  options:
    default: false
    description: Disable external buildpacks. Only admin buildpacks and system buildpacks
      will be available to users.
    required: true
- name: DOMAIN
  options:
    example: my-scf-cluster.com
    required: true
    description: Base domain of the SCF cluster.
- name: DOPPLER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - doppler
    - log-cache
    - metron
    description: PEM-encoded certificate.
    required: true
  type: certificate
- name: DOPPLER_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key.
    required: true
- name: DROPLET_MAX_STAGED_STORED
  options:
    default: 5
    description: The number of versions of an application to keep. You will be able
      to rollback to this amount of versions.
    required: true

- name: EIRINI_CERT_COPIER_IMAGE
  options:
    default: 'splatform/eirini-cert-copier:1.0.0.4.gd8e7208'
    description: "The docker image used by Eirini to register the image registry CA cert with Docker, on each Kubernetes node"
    imagename: true
- name: EIRINI_EIRINI_EXTENSIONS_SERVICE_HOST
  options:
    type: environment
    description: "The Eirini extensions service ClusterIP (automatically set by Kubernetes)"
- name: EIRINI_FLUENTD_IMAGE
  options:
    default: 'eirini/loggregator-fluentd:0.1.0'
    description: "The docker image used by Eirini to consume Kubernetes container logs"
    imagename: true
- name: EIRINI_IMAGE
  options:
    default: 'eirini/recipe:ci-24.0.0'
    description: "Docker Image used for staging apps deployed using Eirini"
    imagename: true
- name: EIRINI_KUBE_HEAPSTER_ADDRESS
  options:
    default: 'http://heapster.kube-system/apis/metrics/v1alpha1'
    description: "Address of Kubernetes' Heapster installation, used for reading Cloud Foundry app metrics."
- name: EIRINI_KUBE_NAMESPACE
  options:
    default: 'eirini'
    description: "The namespace used by Eirini for deploying applications."
- name: EIRINI_PERSI_NFS_BROKER_PASSWORD
  options:
    description: Basic auth password to verify on incoming Service Broker requests
    secret: true
    required: true
  type: password
- name: EIRINI_PERSI_PLANS
  options:
    description: "Array of plans that the Eirini persi broker will expose to Cloud Foundry."
    default: '[]'
    example: |
      - id: "dafault-storageclass"
        name: "default"
        description: "Eirini persistence broker"
        free: true
        kube_storage_class: "persistent"
        default_size: "1Gi"
- name: ENABLE_SECURITY_EVENT_LOGGING
  options:
    default: 'false'
    description: "By default, Cloud Foundry does not enable Cloud Controller request
      logging. To enable this feature, you must set this property to \"true\". You
      can learn more about the format of the logs here https://docs.cloudfoundry.org/loggregator/cc-uaa-logging.html#cc
      \n"
- name: FEATURE_EIRINI_ENABLED
  options:
    type: environment
    default: 'false'
    description: "Whether to enable the Eirini component, which deploys applications on Kubernetes. This causes Diego to be disabled."
- name: FORCE_FORWARDED_PROTO_AS_HTTPS
  options:
    default: false
    description: Enables setting the X-Forwarded-Proto header if SSL termination happened
      upstream and the header value was set incorrectly. When this property is set
      to true, the gorouter sets the header X-Forwarded-Proto to https. When this
      value set to false, the gorouter sets the header X-Forwarded-Proto to the protocol
      of the incoming request.
    required: true
- name: GALERA_HEALTHCHECK_ENDPOINT_DATABASE_PASSWORD
  options:
    previous_names:
    - MYSQL_GALERA_HEALTHCHECK_ENDPOINT_PASSWORD
    secret: true
    description: Password used to authenticate to the MySQL Galera healthcheck endpoint.
    required: true
  type: password
- name: GALERA_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - galera_server_certificate
    description: A PEM-encoded TLS certificate for the Galera server.
    required: true
  type: certificate
- name: GALERA_SERVER_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key for the Galera server.
    required: true
- name: GARDEN_APPARMOR_PROFILE
  options:
    default: garden-default
    description: AppArmor profile name for garden-runc; set this to empty string to
      disable AppArmor support
- name: GARDEN_DISABLE_BTRFS
  options:
    default: ''
    description: An empty value means BTRFS is used. It's set to "true" by a script
      if GARDEN_ROOTFS_DRIVER is set to overlay-xfs.
    type: environment
- name: GARDEN_DOCKER_REGISTRY
  options:
    default: registry-1.docker.io
    description: URL pointing to the Docker registry used for fetching Docker images.
      If not set, the Docker service default is used.
    required: true
- name: GARDEN_LINUX_DNS_SERVER
  options:
    default: ''
    description: Override DNS servers to be used in containers; defaults to the same
      as the host.
- name: GARDEN_ROOTFS_DRIVER
  options:
    default: btrfs
    description: The filesystem driver to use (btrfs or overlay-xfs).
    required: true
    internal: true
- name: GO_LOG_LEVEL
  options:
    type: environment
    description: The log level for go components. This parameter is not supposed
      to be set by the user. To change the cluster's log level set the parameter
      `LOG_LEVEL` instead, from which this one is derived.
- name: HELM_IS_INSTALL
  options:
    type: environment
    description: >
      This is an environment variable built-in by fissile.
      It's set directly from the Release.IsInstall Helm property.
- name: HOSTNAME
  options:
    description: The host name of the container.  This should be automatic and should
      not be prompted.
    type: environment
- name: HTTPS_PROXY
  options:
    required: false
    description: Location of the proxy to use for secure web access.
- name: HTTP_PROXY
  options:
    required: false
    description: Location of the proxy to use for regular web access.
- name: INSECURE_DOCKER_REGISTRIES
  options:
    default: ''
    example: '"docker-registry.example.com:80", "hello.example.org:443"'
    description: >
      A comma-separated whitelist of insecure Docker registries in the
      form of '<HOSTNAME|IP>:PORT'. Each registry must be quoted separately.
- name: INTERNAL_API_PASSWORD
  options:
    secret: true
    description: Basic auth password for access to the Cloud Controller's internal
      API.
    required: true
  type: password
- name: INTERNAL_CA_CERT
  options:
    secret: true
    is_ca: true
    description: PEM-encoded CA certificate used to sign the TLS certificate used
      by all components to secure their communications.
    required: true
  type: certificate
- name: INTERNAL_CA_CERT_KEY
  options:
    secret: true
    description: PEM-encoded CA key.
    required: true
- name: KUBERNETES_CLUSTER_DOMAIN
  options:
    type: environment
    description: >
      The cluster domain used by Kubernetes.
      If left empty, each container will try to determine the correct value based on /etc/resolv.conf
      You can read more about it in the Kubernetes Documentation https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/
- name: KUBERNETES_NAMESPACE
  options:
    type: environment
    description: The name of the kubernetes namespace all components will run in.
      This parameter cannot be set by the user. Its value is supplied by the kubernetes
      runtime.

- name: KUBERNETES_SERVICE_HOST
  options:
    type: environment
    description: >
      This is an environment variable set by Kubernetes.
      We have to pass it through the templating mechanism, because monit doesn't keep the entrypoint's environment.
- name: KUBERNETES_SERVICE_PORT
  options:
    type: environment
    description: >
      This is an environment variable set by Kubernetes.
      We have to pass it through the templating mechanism, because monit doesn't keep the entrypoint's environment.


- name: KUBERNETES_STORAGE_CLASS_PERSISTENT
  options:
    type: environment
    description: >
      Storage class used for SCF acceptance tests.
- name: KUBE_AZ
  options:
    type: environment
    default: z1
    description: >
      A string representing the availability zone a container is running in.
      Shouldn't be changed from its default value of z1.
- name: KUBE_COMPONENT_INDEX
  options:
    type: environment
    description: >
      This is an environment variable built-in by fissile.
      It's set to a numeric index for roles with multiple replicas.
- name: KUBE_NATS_CLUSTER_IPS
  options:
    type: environment
    description: A comma-separated list of IP addresses for the machines of the nats
      sub-cluster. This parameter cannot be set by the user. Its value is automatically
      computed during cluster setup.
- name: KUBE_PZ
  options:
    type: environment
    default: ''
    description: >
      A string representing the placement tag a container is running in.
- name: KUBE_SECRETS_GENERATION_COUNTER
  options:
    type: environment
    description: >
      This is an environment variable built-in by fissile.
      It's automatically set to the kube.secrets_generation_counter Helm value, which controls secret rotation.
- name: KUBE_SECRETS_GENERATION_NAME
  options:
    type: environment
    description: >
      This is an environment variable built-in by fissile.
      Its default value is 'secret-1' and cannot be set by the user.
- name: KUBE_SIZING_MYSQL_COUNT
  options:
    description: The number of mysql replicas deployed. This value is set automatically
      by the helm charts of SCF.
- name: KUBE_SIZING_NATS_COUNT
  options:
    description: The number of nats replicas deployed. This value is set automatically
      by the helm charts of SCF.
- name: KUBE_SIZING_TCP_ROUTER_PORTS_TCP_ROUTE_MAX
  options:
    description: Highest internal TCP routing port. This value is set automatically
      by the helm charts of SCF.
- name: KUBE_SIZING_TCP_ROUTER_PORTS_TCP_ROUTE_MIN
  options:
    description: Lowest internal TCP routing port. This value is set automatically
      by the helm charts of SCF.
- name: LOCKET_DATABASE_PASSWORD
  options:
    previous_names:
    - MYSQL_DIEGO_LOCKET_PASSWORD
    description: Database password for the diego locket service.
    secret: true
    required: true
  type: password
- name: LOGGREGATOR_AGENT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - localhost
    - metron
    description: PEM-encoded certificate.
    required: true
  type: certificate
- name: LOGGREGATOR_AGENT_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key.
    required: true
- name: LOGGREGATOR_CLIENT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded client certificate for loggregator mutual authentication
    required: true
  type: certificate
- name: LOGGREGATOR_CLIENT_CERT_KEY
  options:
    secret: true
    description: PEM-encoded client key for loggregator mutual authentication
    required: true
- name: LOGGREGATOR_FORWARD_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded client certificate for loggregator forwarder authentication
    required: true
  type: certificate
- name: LOGGREGATOR_FORWARD_CERT_KEY
  options:
    secret: true
    description: PEM-encoded client key for loggregator forwarder authentication
    required: true
- name: LOG_CACHE_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - log-cache
    description: PEM-encoded certificate.
    required: true
  type: certificate
- name: LOG_CACHE_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key.
    required: true
- name: LOG_CACHE_CF_AUTH_PROXY_EXTERNAL_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - log-cache
    description: The TLS cert for the auth proxy.
    required: true
  type: certificate
- name: LOG_CACHE_CF_AUTH_PROXY_EXTERNAL_CERT_KEY
  options:
    secret: true
    description: The TLS key for the auth proxy.
    required: true
- name: LOG_CACHE_TO_LOGGREGATOR_AGENT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - log-cache
    description: PEM-encoded certificate.
    required: true
  type: certificate
- name: LOG_CACHE_TO_LOGGREGATOR_AGENT_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key.
    required: true
- name: LOG_LEVEL
  options:
    default: info
    description: >
      The cluster's log level: off, fatal, error, warn, info, debug, debug1, debug2.
    required: true
- name: MAX_APP_DISK_IN_MB
  options:
    default: 2048
    description: The maximum amount of disk a user can request for an application
      via manifest, command line, etc., in MB. See also DEFAULT_APP_DISK_IN_MB for
      the standard amount.
    required: true
- name: MAX_HEALTH_CHECK_TIMEOUT
  options:
    default: 180
    description: Maximum health check timeout that can be set for an app, in seconds.
    required: true
- name: MONIT_PASSWORD
  options:
    secret: true
    description: Password used for the monit API.
    required: true
  type: password
- name: MYSQL_ADMIN_PASSWORD
  options:
    secret: true
    description: The password for the MySQL server admin user.
    required: true
  type: password
- name: MYSQL_CLUSTER_HEALTH_PASSWORD
  options:
    secret: true
    description: The password for the cluster logger health user.
    required: true
  type: password
- name: MYSQL_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - "mysql-set.{{ .KUBERNETES_NAMESPACE }}.svc.{{ .KUBERNETES_CLUSTER_DOMAIN }}"
    - "mysql-proxy-set.{{ .KUBERNETES_NAMESPACE }}.svc.{{ .KUBERNETES_CLUSTER_DOMAIN }}"
    description: A PEM-encoded TLS certificate for the MySQL server.
    required: true
  type: certificate
- name: MYSQL_SERVER_CERT_KEY
  options:
    secret: true
    description: A PEM-encoded TLS key for the MySQL server.
    required: true
- name: NATS_PASSWORD
  options:
    secret: true
    description: The password for access to NATS.
    required: true
  type: password
- name: NGINX_LOG_LEVEL
  options:
    type: environment
    description: The log level for nginx. This parameter is not supposed to be set
      by the user. To change the cluster's log level set the parameter `LOG_LEVEL`
      instead, from which this one is derived.
- name: NGINX_MAX_REQUEST_BODY_SIZE
  options:
    default: 2048
    description: Sets the maximum allowed size of the client request body, specified
      in the “Content-Length” request header field, in megabytes. If the size in a
      request exceeds the configured value, the 413 (Request Entity Too Large) error
      is returned to the client. Please be aware that browsers cannot correctly display
      this error. Setting size to 0 disables checking of client request body size.
      This limits application uploads, buildpack uploads, etc.
    required: true
- name: NO_PROXY
  options:
    description: Comma separated list of IP addresses and domains which should not
      be directoed through a proxy, if any.
    required: false
- name: PERSI_NFS_ALLOWED_OPTIONS
  options:
    description: Comma separated list of white-listed options that may be set during
      create or bind operations.
    example: uid,gid,allow_root,allow_other,nfs_uid,nfs_gid,auto_cache,fsname,username,password
    default: uid,gid,auto_cache,username,password
- name: PERSI_NFS_BROKER_PASSWORD
  options:
    description: Basic auth password to verify on incoming Service Broker requests
    secret: true
    required: true
  type: password
- name: PERSI_NFS_DATABASE_PASSWORD
  options:
    previous_names:
    - MYSQL_PERSI_NFS_PASSWORD
    description: Database password for storing broker state for the Persi NFS Broker
    secret: true
    required: true
  type: password
- name: PERSI_NFS_DEFAULT_OPTIONS
  options:
    description: Comma separated list of default values for nfs mount options.  If
      a default is specified with an option not included in PERSI_NFS_ALLOWED_OPTIONS,  then
      this default value will be set and it won't be overridable.
- name: PERSI_NFS_DRIVER_ALLOWED_IN_MOUNT
  options:
    description: >
      Comma separated list of white-listed options that may be accepted
      in the mount_config options. Note a specific 'sloppy_mount:true' volume option
      tells the driver to ignore non-white-listed options, while a 'sloppy_mount:false'
      tells the driver to fail fast instead when receiving a non-white-listed option."
    example: allow_root,allow_other,nfs_uid,nfs_gid,auto_cache,sloppy_mount,fsname
    default: auto_cache
- name: PERSI_NFS_DRIVER_ALLOWED_IN_SOURCE
  options:
    description: Comma separated list of white-listed options that may be configured
      in supported in the  mount_config.source URL query params.
    example: uid,gid,auto-traverse-mounts,dircache
    default: uid,gid
- name: PERSI_NFS_DRIVER_DEFAULT_IN_MOUNT
  options:
    description: >
      Comma separated list default values for options that may be configured
      in the mount_config options, formatted as 'option:default'. If an option is
      not specified in the volume mount, or the option is not white-listed, then the
      specified default value will be used instead.
    example: allow_root:false,nfs_uid:2000,nfs_gid:2000,auto_cache:true,sloppy_mount:true
    default: auto_cache:true
- name: PERSI_NFS_DRIVER_DEFAULT_IN_SOURCE
  options:
    description: >
      Comma separated list of default values for options in the source
      URL query params, formatted as 'option:default'. If an option is not specified
      in the volume mount,  or the option is not white-listed, then the specified
      default value will be applied.
- name: PERSI_NFS_DRIVER_DISABLE
  options:
    description: Disable Persi NFS driver
    default: 'false'
- name: PERSI_NFS_DRIVER_LDAP_HOST
  options:
    description: LDAP server host name or ip address (required for LDAP integration
      only)
    default: ''
- name: PERSI_NFS_DRIVER_LDAP_PASSWORD
  options:
    description: LDAP service account password (required for LDAP integration only)
    default: "-"
    secret: true
- name: PERSI_NFS_DRIVER_LDAP_PORT
  options:
    description: LDAP server port (required for LDAP integration only)
    default: '389'
- name: PERSI_NFS_DRIVER_LDAP_PROTOCOL
  options:
    description: LDAP server protocol (required for LDAP integration only)
    default: tcp
- name: PERSI_NFS_DRIVER_LDAP_USER
  options:
    description: LDAP service account user name (required for LDAP integration only)
    default: ''
- name: PERSI_NFS_DRIVER_LDAP_USER_FQDN
  options:
    description: LDAP fqdn for user records we will search against when looking up
      user uids (required for LDAP integration only)
    example: cn=Users,dc=corp,dc=test,dc=com
    default: ''
- name: PZ_LABEL_NAME
  options:
    default: ''
    description: The name of the metadata label to query on worker
      nodes to get placement tag information, also known as isolation
      segments. When set, the cells will query their worker node for
      placement information and inject the result into cloudfoundry
      via the KUBE_PZ parameter. When left to the default no custom
      placement processing is done.
    internal: true
- name: REP_SERVER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    role_name: diego-cell
    alternative_names:
    - 127.0.0.1
    description: PEM-encoded server certificate
    required: true
  type: certificate
- name: REP_SERVER_CERT_KEY
  options:
    secret: true
    description: PEM-encoded server key
    required: true
- name: ROOTFS_TRUSTED_CERTS
  options:
    default: ''
    description: Certficates to add to the rootfs trust store. Multiple certs are
      possible by concatenating their definitions into one big block of text.
- name: ROUTER_BALANCING_ALGORITHM
  options:
    default: round-robin
    description: The algorithm used by the router to distribute requests for a route
      across backends. Supported values are round-robin and least-connection.
- name: ROUTER_CLIENT_CERT_VALIDATION
  options:
    description: How to handle client certificates. Supported values are none, request,
      or require. See https://docs.cloudfoundry.org/adminguide/securing-traffic.html#gorouter_mutual_auth
      for more information.
    default: request
- name: ROUTER_FORWARDED_CLIENT_CERT
  options:
    default: always_forward
    description: How to handle the x-forwarded-client-cert (XFCC) HTTP header. Supported
      values are always_forward, forward, and sanitize_set. See https://docs.cloudfoundry.org/concepts/http-routing.html
      for more information.
- name: ROUTER_SERVICES_SECRET
  options:
    secret: true
    description: Support for route services is disabled when no value is configured.
      A robust passphrase is recommended.
    required: true
  type: password
- name: ROUTER_SSL_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - "*.{{.DOMAIN}}"
    description: The public ssl cert for ssl termination. Will be ignored if ROUTER_TLS_PEM
      is set.
    required: true
  type: certificate
- name: ROUTER_SSL_CERT_KEY
  options:
    secret: true
    description: The private ssl key for ssl termination. Will be ignored if ROUTER_TLS_PEM
      is set.
    required: true
- name: ROUTER_STATUS_PASSWORD
  options:
    secret: true
    description: Password for HTTP basic auth to the varz/status endpoint.
    required: true
  type: password
- name: ROUTER_TLS_PEM
  options:
    description: Array of private keys and certificates used for TLS handshakes with
      downstream clients. Each element in the array is an object containing fields
      'private_key' and 'cert_chain', each of which supports a PEM block. This setting
      overrides ROUTER_SSL_CERT and ROUTER_SSL_KEY.
    example: |
      - cert_chain: |
          -----BEGIN CERTIFICATE-----
          -----END CERTIFICATE-----
          -----BEGIN CERTIFICATE-----
          -----END CERTIFICATE-----
        private_key: |
          -----BEGIN RSA PRIVATE KEY-----
          -----END RSA PRIVATE KEY-----
    secret: true
- name: ROUTING_API_DATABASE_PASSWORD
  options:
    previous_names:
    - MYSQL_ROUTING_API_PASSWORD
    secret: true
    description: The password for access to MySQL by the routing-api
    required: true
  type: password
- name: SCF_LOG_HOST
  options:
    internal: true
    description: The log destination to talk to. This has to point to a syslog server.
- name: SCF_LOG_PORT
  options:
    internal: true
    description: The port used by rsyslog to talk to the log destination. It defaults
      to 514, the standard port of syslog.
    default: 514
- name: SCF_LOG_PROTOCOL
  options:
    internal: true
    default: tcp
    description: The protocol used by rsyslog to talk to the log destination. The
      allowed values are tcp, and udp. The default is tcp.
    required: true
- name: STAGING_TIMEOUT
  options:
    default: 900
    description: Timeout for staging an app, in seconds.
    required: true
- name: STAGING_UPLOAD_PASSWORD
  options:
    secret: true
    description: The password for access to the uploader of staged droplets.
    required: true
  type: password
- name: SUPPORT_ADDRESS
  options:
    default: https://scc.suse.com
    description: Support contact information for the cluster
    required: true
- name: SYNC_INTEGRATION_TESTS_FOCUS
  options:
    description: >
      Regex for which SITS tests the test runner should focus on executing.
- name: SYNC_INTEGRATION_TESTS_NODES
  options:
    default: 4
    description: >
      The number of parallel test executors to spawn for Cloud Foundry
      sync integration tests.
- name: SYNC_INTEGRATION_TESTS_SKIP
  options:
    description: >
      Regex for which SITS tests the test runner should skip.
- name: SYNC_INTEGRATION_TESTS_VERBOSE
  options:
    default: false
    description: >
      Whether the output of the sync integration tests should be verbose or not.
- name: SYSLOG_ADAPT_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - adapter
    description: PEM-encoded certificate
    required: true
  type: certificate
- name: SYSLOG_ADAPT_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key.
    required: true
- name: SYSLOG_RLP_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    alternative_names:
    - syslog_rlp
    - reverselogproxy
    description: PEM-encoded certificate
    required: true
  type: certificate
- name: SYSLOG_RLP_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key.
    required: true
- name: SYSLOG_SCHED_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded certificate
    required: true
  type: certificate
- name: SYSLOG_SCHED_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key.
    required: true
- name: TCP_DOMAIN
  options:
    example: tcp.my-scf-cluster.com
    required: true
    description: TCP routing domain of the SCF cluster; only used for testing;
- name: TPS_CC_CLIENT_CRT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded client certificate for internal communication between
      the cloud controller and TPS.
    required: true
  type: certificate
- name: TPS_CC_CLIENT_CRT_KEY
  options:
    secret: true
    description: PEM-encoded client key for internal communication between the cloud
      controller and TPS.
    required: true
- name: TRAFFICCONTROLLER_CERT
  options:
    secret: true
    ca: INTERNAL_CA_CERT
    description: PEM-encoded certificate for communication with the traffic controller
      of the log infra structure.
    required: true
  type: certificate
- name: TRAFFICCONTROLLER_CERT_KEY
  options:
    secret: true
    description: PEM-encoded key for communication with the traffic controller of
      the log infra structure.
    required: true
- name: TRUSTED_CERTS
  options:
    description: Concatenation of trusted CA certificates to be made available on
      the cell.
- name: UAA_ADMIN_CLIENT_SECRET
  options:
    secret: true
    description: The password of the admin client - a client named admin with uaa.admin
      as an authority.
    required: true
- name: UAA_CA_CERT
  options:
    description: The CA certificate for UAA
    secret: true
- name: UAA_CLIENTS_CC_ROUTING_SECRET
  options:
    secret: true
    description: The password for UAA access by the Routing API.
    required: true
  type: password
- name: UAA_CLIENTS_CC_SERVICE_DASHBOARDS_CLIENT_SECRET
  options:
    secret: true
    description: Used for third party service dashboard SSO.
  type: password
- name: UAA_CLIENTS_CC_SERVICE_KEY_CLIENT_SECRET
  options:
    secret: true
    description: Used for fetching service key values from CredHub.
    required: true
  type: password
- name: UAA_CLIENTS_CF_SMOKE_TESTS_CLIENT_SECRET
  options:
    secret: true
    description: Client secret for the CF smoke tests job
    required: true
  type: password
- name: UAA_CLIENTS_CF_USB_SECRET
  options:
    secret: true
    description: The password for UAA access by the Universal Service Broker.
  type: password
- name: UAA_CLIENTS_CLOUD_CONTROLLER_USERNAME_LOOKUP_SECRET
  options:
    secret: true
    description: The password for UAA access by the Cloud Controller for fetching
      usernames.
    required: true
  type: password
- name: UAA_CLIENTS_CREDHUB_USER_CLI_SECRET
  options:
    secret: true
    description: The password for UAA access by the client for the user-accessible credhub
    required: true
  type: password
- name: UAA_CLIENTS_DIEGO_SSH_PROXY_SECRET
  options:
    secret: true
    description: The password for UAA access by the SSH proxy.
    required: true
  type: password
- name: UAA_CLIENTS_DOPPLER_SECRET
  options:
    secret: true
    description: The password for UAA access by doppler.
    required: true
  type: password
- name: UAA_CLIENTS_GOROUTER_SECRET
  options:
    secret: true
    description: The password for UAA access by the gorouter.
    required: true
  type: password
- name: UAA_CLIENTS_ROUTING_API_CLIENT_SECRET
  options:
    secret: true
    description: The OAuth client secret used by the routing-api.
    required: true
  type: password
- name: UAA_CLIENTS_SCF_AUTO_CONFIG_SECRET
  options:
    secret: true
    description: The password for UAA access by the task creating the cluster administrator
      user
    required: true
  type: password
- name: UAA_CLIENTS_TCP_EMITTER_SECRET
  options:
    secret: true
    description: The password for UAA access by the TCP emitter.
    required: true
  type: password
- name: UAA_CLIENTS_TCP_ROUTER_SECRET
  options:
    secret: true
    description: The password for UAA access by the TCP router.
    required: true
  type: password
- name: UAA_HOST
  options:
    description: The host name of the UAA server (root zone)
    required: true
- name: UAA_PORT
  options:
    default: 2793
    description: The tcp port the UAA server (root zone) listens on for requests.
- name: USE_DIEGO_PRIVILEGED_CONTAINERS
  options:
    default: false
    description: Whether or not to use privileged containers for buildpack based applications.
      Containers with a docker-image-based rootfs will continue to always be unprivileged.
    required: true
- name: USE_STAGER_PRIVILEGED_CONTAINERS
  options:
    default: false
    description: Whether or not to use privileged containers for staging tasks.
    required: true
